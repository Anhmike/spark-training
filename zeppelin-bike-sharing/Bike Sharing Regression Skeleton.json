{"paragraphs":[{"text":"%md\n# Pretty Printing","dateUpdated":"2017-01-22T16:16:12+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196948_1449718489","id":"20160617-174039_493869597","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Pretty Printing</h1>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:87","dateFinished":"2017-01-22T16:16:12+0000","dateStarted":"2017-01-22T16:16:12+0000","focus":true},{"text":"implicit class ZeppelinOutput[T](ds:org.apache.spark.sql.Dataset[T]) {\n    def toZeppelin(limit:Int = -1)  = {\n        val df = ds.toDF\n        println(\"%table\")\n        println(df.schema.map(_.name).mkString(\"\\t\"))\n        val data = if (limit <= 0) df else df.limit(limit)\n        data.collect.foreach(row => println(row.mkString(\"\\t\")))\n    }\n}","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196948_1449718489","id":"20160617-174039_442021124","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:88"},{"text":"%md\n# Load Data into Hive","dateUpdated":"2017-01-22T16:16:07+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196948_1449718489","id":"20160617-174039_903096095","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Load Data into Hive</h1>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:89","dateFinished":"2017-01-22T16:16:08+0000","dateStarted":"2017-01-22T16:16:07+0000","focus":true},{"text":"%sql\ncreate database if not exists training","dateUpdated":"2017-01-22T16:07:18+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196948_1449718489","id":"20170108-055306_2008372397","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:90"},{"text":"%sql\ncreate external table if not exists training.bike_sharing(\n    row_id int,\n    date string,\n    season int,\n    year int,\n    month int,\n    hour int,\n    holiday int,\n    weekday int,\n    workingday int,\n    weather int,\n    temperature double,\n    apparent_temperature double,\n    humidity double,\n    wind_speed double,\n    casual int,\n    registered int,\n    counter int) \nROW FORMAT DELIMITED FIELDS TERMINATED BY ','\nSTORED AS TEXTFILE\nLOCATION 's3://dimajix-training/data/bike-sharing'","dateUpdated":"2017-01-22T16:10:33+0000","config":{"editorMode":"ace/mode/sql","colWidth":12,"tableHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196949_1449333740","id":"20160617-174039_2069135316","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:91"},{"text":"%sql\nselect * from training.bike_sharing limit 10","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/sql","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196949_1449333740","id":"20160617-174039_1754560141","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:92"},{"text":"%md\n# Alternative: Load Data from File","dateUpdated":"2017-01-22T16:16:16+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196956_1446640497","id":"20160617-174039_1794332830","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Alternative: Load Data from File</h1>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:93","dateFinished":"2017-01-22T16:16:16+0000","dateStarted":"2017-01-22T16:16:16+0000","focus":true},{"text":"import org.apache.spark.sql.Row\nimport org.apache.spark.sql.types._\n\nval schema = StructType(Array(\n    StructField(\"row_id\",StringType,true),\n    StructField(\"date\",StringType, true),\n    StructField(\"season\",IntegerType, true),\n    StructField(\"year\",IntegerType, true),\n    StructField(\"month\",IntegerType, true),\n    StructField(\"hour\",IntegerType, true),\n    StructField(\"holiday\",IntegerType, true),\n    StructField(\"weekday\",IntegerType, true),\n    StructField(\"workingday\",IntegerType, true),\n    StructField(\"weather\",IntegerType, true),\n    StructField(\"temperature\",FloatType, true),\n    StructField(\"apparent_temperature\",FloatType, true),\n    StructField(\"humidity\",FloatType, true),\n    StructField(\"wind_speed\",FloatType, true),\n    StructField(\"casual\",IntegerType, true),\n    StructField(\"registered\",IntegerType, true),\n    StructField(\"counter\",IntegerType, true)\n    ))\n    \nval data = spark.read.schema(schema).csv(\"s3://dimajix-training/data/bike-sharing\")","dateUpdated":"2017-01-22T16:15:40+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196956_1446640497","id":"20160617-174039_239018989","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:94","focus":true},{"text":"data.toZeppelin(10)","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"row_id","index":0,"aggr":"sum"}],"values":[{"name":"date","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"row_id","index":0,"aggr":"sum"},"yAxis":{"name":"date","index":1,"aggr":"sum"}}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196956_1446640497","id":"20160617-174039_1397728233","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:95"},{"text":"%md\n# Prepare Data","dateUpdated":"2017-01-22T16:16:22+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196958_1447409995","id":"20160617-174039_294797498","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Prepare Data</h1>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:96","dateFinished":"2017-01-22T16:16:23+0000","dateStarted":"2017-01-22T16:16:23+0000","focus":true},{"text":"val data = sqlContext.table(\"training.bike_sharing\")\nval ddata = data.select(\n        $\"date\",\n        unix_timestamp($\"date\", \"yyyy-MM-dd\").cast(DoubleType).alias(\"ts\"),\n        $\"season\".cast(\"Double\"),\n        $\"year\".cast(\"Double\"),\n        $\"month\".cast(\"Double\"),\n        $\"hour\".cast(\"Double\"),\n        $\"holiday\".cast(\"Double\"),\n        $\"weekday\".cast(\"Double\"),\n        $\"workingday\".cast(\"Double\"),\n        $\"weather\".cast(\"Double\"),\n        $\"temperature\",\n        $\"apparent_temperature\",\n        $\"humidity\",\n        $\"wind_speed\",\n        $\"casual\".cast(DoubleType),\n        $\"registered\".cast(DoubleType),\n        $\"counter\".cast(DoubleType)\n    )\n    ","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196958_1447409995","id":"20160617-174039_416775257","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:97"},{"text":"%md\n# Cache Data\n\nSince ddata will now be our basis for all sorts of processing, we want to cache it.","dateUpdated":"2017-01-22T16:16:25+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196958_1447409995","id":"20160617-174039_1797571532","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Cache Data</h1>\n<p>Since ddata will now be our basis for all sorts of processing, we want to cache it.</p>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:98","dateFinished":"2017-01-22T16:16:26+0000","dateStarted":"2017-01-22T16:16:26+0000","focus":true},{"text":"ddata.cache()","dateUpdated":"2017-01-22T16:16:27+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196964_1431250541","id":"20160617-174039_984792328","dateCreated":"2017-01-22T16:06:36+0000","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:99","dateFinished":"2017-01-22T16:16:27+0000","dateStarted":"2017-01-22T16:16:27+0000","focus":true},{"text":"%md\n# Make some nice Pictures\n\nThe original data contains rents per hour, we want to have the data per day. Maybe we can already see some patterns here?","dateUpdated":"2017-01-22T16:16:37+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196964_1431250541","id":"20160617-174039_748189267","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Make some nice Pictures</h1>\n<p>The original data contains rents per hour, we want to have the data per day. Maybe we can already see some patterns here?</p>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:100","dateFinished":"2017-01-22T16:16:37+0000","dateStarted":"2017-01-22T16:16:37+0000","focus":true},{"text":"// Generate Table with summed data per day","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"lineChart","height":300,"optionOpen":false,"keys":[{"name":"ts","index":0,"aggr":"sum"}],"values":[{"name":"sum(counter)","index":1,"aggr":"sum"}],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196965_1430865793","id":"20160617-174039_1300257284","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:101"},{"text":"// Generate Table with summed data per day, only for casual renters","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"lineChart","height":300,"optionOpen":false,"keys":[{"name":"ts","index":0,"aggr":"sum"}],"values":[],"groups":[],"scatter":{"xAxis":{"name":"ts","index":0,"aggr":"sum"}}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196965_1430865793","id":"20160617-174039_630580316","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:102"},{"text":"// Generate Table with summed data per day, only for registered renters","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"lineChart","height":300,"optionOpen":false,"keys":[{"name":"ts","index":0,"aggr":"sum"}],"values":[{"name":"sum(counter)","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"ts","index":0,"aggr":"sum"},"yAxis":{"name":"sum(counter)","index":1,"aggr":"sum"}}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196965_1430865793","id":"20160617-174039_331573067","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:103"},{"text":"%md\n# Initial Statistics on Values","dateUpdated":"2017-01-22T16:16:39+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196965_1430865793","id":"20160617-174039_261413913","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Initial Statistics on Values</h1>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:104","dateFinished":"2017-01-22T16:16:39+0000","dateStarted":"2017-01-22T16:16:39+0000","focus":true},{"text":"// Print some initial statistics for every column in the dataframe using the stats() method from RDD\n\n","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196965_1430865793","id":"20160617-174039_1979577676","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:105"},{"text":"%md\n# Linear Regression\n\nNow we want to perform all steps required for creating a predictive model via a linear regression. We will do this in multiple steps:\n\n1. Create a Helper Function for Extracting Feature Vectors\n2. Transform the DataFrame using Helper Function\n3. Split Data into Training Data and Test Data\n4. Create Model\n5. Perform Predictions\n6. Evaluate Model","dateUpdated":"2017-01-22T16:16:42+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196966_1432020039","id":"20160617-174039_1945341208","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Linear Regression</h1>\n<p>Now we want to perform all steps required for creating a predictive model via a linear regression. We will do this in multiple steps:</p>\n<ol>\n<li>Create a Helper Function for Extracting Feature Vectors</li>\n<li>Transform the DataFrame using Helper Function</li>\n<li>Split Data into Training Data and Test Data</li>\n<li>Create Model</li>\n<li>Perform Predictions</li>\n<li>Evaluate Model</li>\n</ol>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:106","dateFinished":"2017-01-22T16:16:42+0000","dateStarted":"2017-01-22T16:16:42+0000","focus":true},{"text":"%md\n## 1. Extract Vectors for Regression\n\nSpark ML requires a special type \"Vector\" for representing features. Therefore we need to build these Vectors from all columns that we want to use as a vector.","dateUpdated":"2017-01-22T16:16:46+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196966_1432020039","id":"20160617-174039_2058640928","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>1. Extract Vectors for Regression</h2>\n<p>Spark ML requires a special type &ldquo;Vector&rdquo; for representing features. Therefore we need to build these Vectors from all columns that we want to use as a vector.</p>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:107","dateFinished":"2017-01-22T16:16:47+0000","dateStarted":"2017-01-22T16:16:47+0000","focus":true},{"text":"import org.apache.spark.ml.linalg.Vectors\n\ndef extract_vector(row:Row, cols:Array[Int]) = ...\n\nprintln(extract_vector(Row(\"Bob\",23.0), Array(1)))\n","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196966_1432020039","id":"20160617-174039_1469040079","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:108"},{"text":"%md\n## 2. Transform DataFrame\n\nNow that we have extract_vector, we can use it in order to extract the relevant features from our DataFrame","dateUpdated":"2017-01-22T16:16:50+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196966_1432020039","id":"20160617-174039_537118194","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>2. Transform DataFrame</h2>\n<p>Now that we have extract_vector, we can use it in order to extract the relevant features from our DataFrame</p>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:109","dateFinished":"2017-01-22T16:16:50+0000","dateStarted":"2017-01-22T16:16:50+0000","focus":true},{"text":"// Use the following columns for extracting the Features\nval cols = Array(1,2,3,4,5,6,7,8,9,10,11,12,13)\n\n// Transform all records ddata into tuples (feature, counter)\n// counter can be found in column row(16)\n// the resulting columns should be called \"features\" and \"counter\"\nval features_labels = ...\n\n// Peek inside the new dataframe\nfeatures_labels.toZeppelin(6)\n","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"features","index":0,"aggr":"sum"}],"values":[{"name":"counter","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"features","index":0,"aggr":"sum"}}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196966_1432020039","id":"20160617-174039_1471718217","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:110"},{"text":"%md\n## 3. Split Data into Training Data and Test Data","dateUpdated":"2017-01-22T16:16:53+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196966_1432020039","id":"20160617-174039_451426973","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>3. Split Data into Training Data and Test Data</h2>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:111","dateFinished":"2017-01-22T16:16:53+0000","dateStarted":"2017-01-22T16:16:53+0000","focus":true},{"text":"// Initialize train_data and test_data\n...\n\nprintln(train_data.count())\nprintln(test_data.count())","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196966_1432020039","id":"20160617-174039_73410360","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:112"},{"text":"%md\n## 4. Perform Simple Linear Regression\n\nWe simply need to create an instance of a LinearRegression, set input and target column names and the prediction column name.","dateUpdated":"2017-01-22T16:16:55+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196973_1427787801","id":"20160617-174039_1152307142","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>4. Perform Simple Linear Regression</h2>\n<p>We simply need to create an instance of a LinearRegression, set input and target column names and the prediction column name.</p>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:113","dateFinished":"2017-01-22T16:16:55+0000","dateStarted":"2017-01-22T16:16:55+0000","focus":true},{"text":"import org.apache.spark.ml.regression._\n\n","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196973_1427787801","id":"20160617-174039_818606948","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:114"},{"text":"%md\n### Peek Inside the Model","dateUpdated":"2017-01-22T16:16:56+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196973_1427787801","id":"20160617-174039_1546732354","result":{"code":"SUCCESS","type":"HTML","msg":"<h3>Peek Inside the Model</h3>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:115","dateFinished":"2017-01-22T16:16:56+0000","dateStarted":"2017-01-22T16:16:56+0000","focus":true},{"text":"","dateUpdated":"2017-01-22T16:16:59+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196973_1427787801","id":"20160617-174039_641126743","dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:116","dateFinished":"2017-01-22T16:16:59+0000","dateStarted":"2017-01-22T16:16:59+0000","result":{"code":"SUCCESS","type":"TEXT","msg":""},"focus":true},{"text":"","dateUpdated":"2017-01-22T16:17:02+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196974_1428942048","id":"20160617-174039_1491712602","dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:117","dateFinished":"2017-01-22T16:17:02+0000","dateStarted":"2017-01-22T16:17:02+0000","result":{"code":"SUCCESS","type":"TEXT","msg":""},"focus":true},{"text":"val statistics = cols.zipWithIndex.map { \n        case (col,idx) => (\n             ddata.schema(col).name, \n             model.coefficients(idx),\n             model.summary.coefficientStandardErrors(idx),\n             model.summary.tValues(idx), \n             model.summary.pValues(idx)\n        )\n    }.toSeq\n    .toDS\n    .withColumnRenamed(\"_1\", \"feature\")\n    .withColumnRenamed(\"_2\", \"coefficient\")\n    .withColumnRenamed(\"_3\", \"stdError\")\n    .withColumnRenamed(\"_4\", \"tValue\")\n    .withColumnRenamed(\"_5\", \"pValue\")\n\n\nstatistics.toZeppelin()","dateUpdated":"2017-01-22T16:06:36+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196974_1428942048","id":"20170108-055714_820098938","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:118"},{"text":"%md\n## 5. Perform Predictions\n\nPredict new Data by applying the model to the test data","dateUpdated":"2017-01-22T16:17:06+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196974_1428942048","id":"20160617-174039_1489606736","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>5. Perform Predictions</h2>\n<p>Predict new Data by applying the model to the test data</p>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:119","dateFinished":"2017-01-22T16:17:06+0000","dateStarted":"2017-01-22T16:17:06+0000","focus":true},{"text":"","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196974_1428942048","id":"20160617-174039_456055226","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:120"},{"text":"%md\n## 6. Evaluate Model\n\nFinally we want to evaluate our model, i.e. calculate a metric which tells us the quality of predictions.","dateUpdated":"2017-01-22T16:17:08+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196974_1428942048","id":"20160617-174039_551047239","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>6. Evaluate Model</h2>\n<p>Finally we want to evaluate our model, i.e. calculate a metric which tells us the quality of predictions.</p>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:121","dateFinished":"2017-01-22T16:17:08+0000","dateStarted":"2017-01-22T16:17:08+0000","focus":true},{"text":"\n","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196974_1428942048","id":"20160617-174039_1501460009","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:122"},{"text":"%md\n# VectorAssembler instead of Manual Feature Extraction\n\nManual feature extraction (i.e. creation of the Vector) is a little bit tedious and not very comfortable. But luckily, there is a valuable helper called VectorAssembler.\n\nWe use it to automatically extract the columns\n\n    season, year, month, hour, holiday, weekday, workingday, weather, \n    temperature, apparent_temperature, humidity, wind_speed\n\ninto the new output column 'features'\n\nSo we will again create a regression, but in a cleaner way.\n\n1. Split Data into Training and Validation Set\n2. Create Features Using Vector Assembler and Train Model\n3. Predict Data\n4. Evaluate Model","dateUpdated":"2017-01-22T16:17:11+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196974_1428942048","id":"20160617-174039_2105519013","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>VectorAssembler instead of Manual Feature Extraction</h1>\n<p>Manual feature extraction (i.e. creation of the Vector) is a little bit tedious and not very comfortable. But luckily, there is a valuable helper called VectorAssembler.</p>\n<p>We use it to automatically extract the columns</p>\n<pre><code>season, year, month, hour, holiday, weekday, workingday, weather, \ntemperature, apparent_temperature, humidity, wind_speed\n</code></pre>\n<p>into the new output column 'features'</p>\n<p>So we will again create a regression, but in a cleaner way.</p>\n<ol>\n<li>Split Data into Training and Validation Set</li>\n<li>Create Features Using Vector Assembler and Train Model</li>\n<li>Predict Data</li>\n<li>Evaluate Model</li>\n</ol>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:123","dateFinished":"2017-01-22T16:17:11+0000","dateStarted":"2017-01-22T16:17:11+0000","focus":true},{"text":"%md\n## Vector Assembler\n\nBefore beginning with the regression, lets have a look how a VectorAssembler works, and why it can help us.","dateUpdated":"2017-01-22T16:17:14+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196979_1439330268","id":"20160617-174039_1222516225","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Vector Assembler</h2>\n<p>Before beginning with the regression, lets have a look how a VectorAssembler works, and why it can help us.</p>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:124","dateFinished":"2017-01-22T16:17:14+0000","dateStarted":"2017-01-22T16:17:14+0000","focus":true},{"text":"\n","dateUpdated":"2017-01-22T16:17:17+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196980_1437406524","id":"20160617-174039_1854142726","dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:125","dateFinished":"2017-01-22T16:17:17+0000","dateStarted":"2017-01-22T16:17:17+0000","result":{"code":"SUCCESS","type":"TEXT","msg":""},"focus":true},{"text":"td.printSchema()","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196980_1437406524","id":"20160617-174039_441594265","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:126"},{"text":"%md\n## 1. Split Train and Test Data\n\nSince we found an easier way to generate features, we split incoming data first and apply the VectorAssembler","dateUpdated":"2017-01-22T16:17:19+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196980_1437406524","id":"20160617-174039_171327823","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>1. Split Train and Test Data</h2>\n<p>Since we found an easier way to generate features, we split incoming data first and apply the VectorAssembler</p>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:127","dateFinished":"2017-01-22T16:17:19+0000","dateStarted":"2017-01-22T16:17:19+0000","focus":true},{"text":"val Array(train_data, test_data) = ddata.randomSplit(Array(0.8,0.2), seed=0)\nprintln(train_data.count())\nprintln(test_data.count())","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196980_1437406524","id":"20160617-174039_1878634181","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:128"},{"text":"%md\n## 2. Perform Regression\n\n1. Apply VectorAssembler\n2. Perform Fitting","dateUpdated":"2017-01-22T16:17:22+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196980_1437406524","id":"20160617-174039_1900101873","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>2. Perform Regression</h2>\n<ol>\n<li>Apply VectorAssembler</li>\n<li>Perform Fitting</li>\n</ol>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:129","dateFinished":"2017-01-22T16:17:22+0000","dateStarted":"2017-01-22T16:17:22+0000","focus":true},{"text":"val asm = ...\n\nval regression = ...\n\nval model = ...","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196980_1437406524","id":"20160617-174039_1930348621","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:130"},{"text":"%md\n## 3. Predict\n\nMake predictions from test data and print some results","dateUpdated":"2017-01-22T16:17:24+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196980_1437406524","id":"20160617-174039_1333817918","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>3. Predict</h2>\n<p>Make predictions from test data and print some results</p>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:131","dateFinished":"2017-01-22T16:17:24+0000","dateStarted":"2017-01-22T16:17:24+0000","focus":true},{"text":"val prediction = ...\n\nprediction.toZeppelin(10)","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196980_1437406524","id":"20160617-174039_2043440440","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:132"},{"text":"%md\n## 4. Evaluate Model\n\nFinally lets evaluate the prediction","dateUpdated":"2017-01-22T16:17:26+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196981_1437021775","id":"20160617-174039_1544992256","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>4. Evaluate Model</h2>\n<p>Finally lets evaluate the prediction</p>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:133","dateFinished":"2017-01-22T16:17:26+0000","dateStarted":"2017-01-22T16:17:26+0000","focus":true},{"text":"","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196981_1437021775","id":"20160617-174039_1460070715","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:134"},{"text":"%md\n# Make new Pictures of Predictions\n\nLet us visually compare the prediction with the true values for the validation data set.","dateUpdated":"2017-01-22T16:17:28+0000","config":{"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196981_1437021775","id":"20160617-174039_112872736","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Make new Pictures of Predictions</h1>\n<p>Let us visually compare the prediction with the true values for the validation data set.</p>\n"},"dateCreated":"2017-01-22T16:06:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:135","dateFinished":"2017-01-22T16:17:28+0000","dateStarted":"2017-01-22T16:17:28+0000","focus":true},{"text":"prediction\n    .groupBy(\"ts\").agg(sum(\"counter\"), sum(\"prediction\")) \n    .orderBy(\"ts\")\n    .toZeppelin()","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"lineChart","height":300,"optionOpen":false,"keys":[{"name":"ts","index":0,"aggr":"sum"}],"values":[{"name":"sum(counter)","index":1,"aggr":"sum"},{"name":"sum(prediction)","index":2,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"ts","index":0,"aggr":"sum"},"yAxis":{"name":"sum(counter)","index":1,"aggr":"sum"}}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196981_1437021775","id":"20160617-174039_824013651","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:136"},{"text":"","dateUpdated":"2017-01-22T16:06:36+0000","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485101196981_1437021775","id":"20160617-174039_75392854","dateCreated":"2017-01-22T16:06:36+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:137"}],"name":"Bike Sharing Regression Skeleton","id":"2C64S6QD2","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}