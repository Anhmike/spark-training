{"paragraphs":[{"text":"%md\n# Pretty Printing\n\nAs usual we first define a helper method for pretty print Spark DataFrames","dateUpdated":"2017-01-09T00:31:22-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483950657012_1116516505","id":"20170109-003057_1724816119","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Pretty Printing</h1>\n<p>As usual we first define a helper method for pretty print Spark DataFrames</p>\n"},"dateCreated":"2017-01-09T00:30:57-0800","dateStarted":"2017-01-09T00:31:17-0800","dateFinished":"2017-01-09T00:31:17-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9964"},{"text":"implicit class ZeppelinOutput[T](ds:org.apache.spark.sql.Dataset[T]) {\n    def toZeppelin(limit:Int = -1)  = {\n        val df = ds.toDF\n        println(\"%table\")\n        println(df.schema.map(_.name).mkString(\"\\t\"))\n        val data = if (limit <= 0) df else df.limit(limit)\n        data.collect.foreach(row => println(row.mkString(\"\\t\")))\n    }\n}","dateUpdated":"2017-01-09T01:01:01-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483950653856_742540574","id":"20170109-003053_1651278420","result":{"code":"SUCCESS","type":"TEXT","msg":"\ndefined class ZeppelinOutput\n"},"dateCreated":"2017-01-09T00:30:53-0800","dateStarted":"2017-01-09T01:01:01-0800","dateFinished":"2017-01-09T01:01:19-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9965"},{"text":"%md\n# Load Station Data\n\nNow we load the station meta data using traditional SparkSQL DataFrame methods. Since the meta data is stored as a simple CSV, this should be simple.","dateUpdated":"2017-01-09T00:28:24-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483950443958_1485969039","id":"20170109-002723_896381522","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Load Station Data</h1>\n<p>Now we load the station meta data using traditional SparkSQL DataFrame methods. Since the meta data is stored as a simple CSV, this should be simple.</p>\n"},"dateCreated":"2017-01-09T00:27:23-0800","dateStarted":"2017-01-09T00:28:21-0800","dateFinished":"2017-01-09T00:28:21-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9966"},{"text":"import org.apache.spark.sql.types.StructType\nimport org.apache.spark.sql.types.StructField\nimport org.apache.spark.sql.types.StringType\nimport org.apache.spark.sql.types.FloatType\nimport org.apache.spark.sql.types.DateType\n\ndef extractFloat = udf((v:String) => if (v != null) v.toFloat else None, FloatType)\n\nval isdSchema = StructType(\n        StructField(\"usaf\", StringType) ::\n        StructField(\"wban\", StringType) ::\n        StructField(\"name\", StringType) ::\n        StructField(\"country\", StringType) ::\n        StructField(\"state\", StringType) ::\n        StructField(\"icao\", StringType) ::\n        StructField(\"latitude\", StringType) ::\n        StructField(\"longitude\", StringType) ::\n        StructField(\"elevation\", StringType) ::\n        StructField(\"date_begin\", DateType) ::\n        StructField(\"date_end\", DateType) ::\n        Nil\n    )\nval isd = sqlContext.read\n    .option(\"header\",\"true\")\n    .option(\"dateFormat\",\"yyyyMMdd\")\n    .schema(isdSchema)\n    .csv(\"/user/training/data/weather/isd-history\")\n    .withColumn(\"latitude\", extractFloat($\"latitude\"))\n    .withColumn(\"longitude\", extractFloat($\"longitude\"))\n    .withColumn(\"elevation\", extractFloat($\"elevation\"))\n    \n\nisd.toZeppelin(10)","dateUpdated":"2017-01-09T01:15:19-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"usaf","index":0,"aggr":"sum"}],"values":[{"name":"wban","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"usaf","index":0,"aggr":"sum"},"yAxis":{"name":"wban","index":1,"aggr":"sum"}}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483950501913_831788640","id":"20170109-002821_386723165","result":{"code":"ERROR","type":"TEXT","msg":"\nimport org.apache.spark.sql.types.StructType\n\nimport org.apache.spark.sql.types.StructField\n\nimport org.apache.spark.sql.types.StringType\n\nimport org.apache.spark.sql.types.FloatType\n\nimport org.apache.spark.sql.types.DateType\n\nextractFloat: org.apache.spark.sql.expressions.UserDefinedFunction\n\nisdSchema: org.apache.spark.sql.types.StructType = StructType(StructField(usaf,StringType,true), StructField(wban,StringType,true), StructField(name,StringType,true), StructField(country,StringType,true), StructField(state,StringType,true), StructField(icao,StringType,true), StructField(latitude,StringType,true), StructField(longitude,StringType,true), StructField(elevation,StringType,true), StructField(date_begin,DateType,true), StructField(date_end,DateType,true))\n\nisd: org.apache.spark.sql.DataFrame = [usaf: string, wban: string ... 9 more fields]\n\n\n\n<console>:39: error: value toZeppelin is not a member of org.apache.spark.sql.DataFrame\n       isd.toZeppelin(10)\n           ^\n"},"dateCreated":"2017-01-09T00:28:21-0800","dateStarted":"2017-01-09T01:15:20-0800","dateFinished":"2017-01-09T01:15:42-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:9967","focus":true},{"text":"isd.printSchema()","dateUpdated":"2017-01-09T01:15:25-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483950602155_-872158614","id":"20170109-003002_1177603813","result":{"code":"SUCCESS","type":"TEXT","msg":"root\n |-- usaf: string (nullable = true)\n |-- wban: string (nullable = true)\n |-- name: string (nullable = true)\n |-- country: string (nullable = true)\n |-- state: string (nullable = true)\n |-- icao: string (nullable = true)\n |-- latitude: float (nullable = true)\n |-- longitude: float (nullable = true)\n |-- elevation: float (nullable = true)\n |-- date_begin: date (nullable = true)\n |-- date_end: date (nullable = true)\n\n"},"dateCreated":"2017-01-09T00:30:02-0800","dateStarted":"2017-01-09T01:15:25-0800","dateFinished":"2017-01-09T01:15:42-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9968","focus":true},{"text":"%md\n# Create a Streaming Context\n\nStreaming is performed using a special StreamingContext, which can be constructed from an existing SparkContext. Additionally a window size for micro batches is required.\n","dateUpdated":"2017-01-09T00:27:15-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483950359165_-1012913771","id":"20170109-002559_1248270322","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Create a Streaming Context</h1>\n<p>Streaming is performed using a special StreamingContext, which can be constructed from an existing SparkContext. Additionally a window size for micro batches is required.</p>\n"},"dateCreated":"2017-01-09T00:25:59-0800","dateStarted":"2017-01-09T00:27:12-0800","dateFinished":"2017-01-09T00:27:12-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9971"},{"text":"import org.apache.spark.streaming.StreamingContext\nimport org.apache.spark.streaming.Seconds\n\nval ssc = new StreamingContext(sc, Seconds(1))","dateUpdated":"2017-01-09T01:27:55-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483950432381_-227717886","id":"20170109-002712_346811562","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.streaming.StreamingContext\n\nimport org.apache.spark.streaming.Seconds\n\nssc: org.apache.spark.streaming.StreamingContext = org.apache.spark.streaming.StreamingContext@7d9a2d18\n"},"dateCreated":"2017-01-09T00:27:12-0800","dateStarted":"2017-01-09T01:27:55-0800","dateFinished":"2017-01-09T01:27:56-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9972","focus":true},{"text":"import org.apache.spark.storage.StorageLevel\n\nval stream = ssc.socketTextStream(\"localhost\", 9977, StorageLevel.MEMORY_ONLY)","dateUpdated":"2017-01-09T01:27:58-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483951801636_885710372","id":"20170109-005001_1008352335","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.storage.StorageLevel\n\nstream: org.apache.spark.streaming.dstream.ReceiverInputDStream[String] = org.apache.spark.streaming.dstream.SocketInputDStream@13a2305d\n"},"dateCreated":"2017-01-09T00:50:01-0800","dateStarted":"2017-01-09T01:27:58-0800","dateFinished":"2017-01-09T01:27:58-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9973","focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483954032366_1011862563","id":"20170109-012712_136743186","dateCreated":"2017-01-09T01:27:12-0800","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11381","text":"%md\n# Extract Weather Data\n\nWe use a small helper class for extracting weather data from the raw data.\n","dateUpdated":"2017-01-09T01:27:41-0800","dateFinished":"2017-01-09T01:27:37-0800","dateStarted":"2017-01-09T01:27:37-0800","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Extract Weather Data</h1>\n<p>We use a small helper class for extracting weather data from the raw data.</p>\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483953986374_1592555922","id":"20170109-012626_729864789","dateCreated":"2017-01-09T01:26:26-0800","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11311","text":"case class WeatherData(\n    date:String,\n    time:String,\n    usaf:String,\n    wban:String,\n    airTemperatureQuality:Int,\n    airTemperature:Float,\n    windSpeedQuality:Int,\n    windSpeed:Float\n)\n\nval weatherData = stream.map { row => \n    val date = row.substring(15,23)\n    val time = row.substring(23,27)\n    val usaf = row.substring(4,10)\n    val wban = row.substring(10,15)\n    val airTemperatureQuality = row.charAt(92).toInt - '0'.toInt\n    val airTemperature = row.substring(87,92).toFloat/10\n    val windSpeedQuality = row.charAt(69) - '0'.toInt\n    val windSpeed = row.substring(65,69).toFloat/10\n\n    WeatherData(date,time,usaf,wban,airTemperatureQuality,airTemperature,windSpeedQuality,windSpeed)\n}\n    ","dateUpdated":"2017-01-09T01:28:00-0800","dateFinished":"2017-01-09T01:28:00-0800","dateStarted":"2017-01-09T01:28:00-0800","result":{"code":"SUCCESS","type":"TEXT","msg":"\ndefined class WeatherData\n\nweatherData: org.apache.spark.streaming.dstream.DStream[WeatherData] = org.apache.spark.streaming.dstream.MappedDStream@857e657\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483954121144_312327766","id":"20170109-012841_979692617","dateCreated":"2017-01-09T01:28:41-0800","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11511","text":"%md\n## Create a Sliding Window","dateUpdated":"2017-01-09T01:29:09-0800","dateFinished":"2017-01-09T01:29:09-0800","dateStarted":"2017-01-09T01:29:09-0800","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Create a Sliding Window</h2>\n"}},{"text":"val windowedData = weatherData.window(Seconds(10), Seconds(1))","dateUpdated":"2017-01-09T01:28:03-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483952085300_-434380073","id":"20170109-005445_504096722","result":{"code":"SUCCESS","type":"TEXT","msg":"\nwindowedData: org.apache.spark.streaming.dstream.DStream[WeatherData] = org.apache.spark.streaming.dstream.WindowedDStream@5344633b\n"},"dateCreated":"2017-01-09T00:54:45-0800","dateStarted":"2017-01-09T01:28:03-0800","dateFinished":"2017-01-09T01:28:03-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9974","focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483954134565_1177844225","id":"20170109-012854_2052710484","dateCreated":"2017-01-09T01:28:54-0800","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11590","text":"%md\n## Performed grouping and Aggregation","dateUpdated":"2017-01-09T01:29:24-0800","dateFinished":"2017-01-09T01:29:24-0800","dateStarted":"2017-01-09T01:29:24-0800","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Performed grouping and Aggregation</h2>\n"}},{"text":"windowedData\n    .transform(rdd => {\n        val weather = rdd.toDS\n        val result = weather\n            .join(isd, weather(\"usaf\") === isd(\"usaf\") && weather(\"wban\") === isd(\"wban\"))\n            .withColumn(\"year\", weather(\"date\").substr(0,4))\n            .groupBy(isd(\"country\"), $\"year\")\n            .agg(\n                min(when(col(\"airTemperatureQuality\") === lit(1), col(\"airTemperature\")).otherwise(9999)).as(\"temp_min\"),\n                max(when(col(\"airTemperatureQuality\") === lit(1), col(\"airTemperature\")).otherwise(-9999)).as(\"temp_max\"),\n                min(when(col(\"windSpeedQuality\") === lit(1), col(\"windSpeed\")).otherwise(9999)).as(\"wind_min\"),\n                max(when(col(\"windSpeedQuality\") === lit(1), col(\"windSpeed\")).otherwise(-9999)).as(\"wind_max\")\n            )\n        result.rdd\n    }).print(10)","dateUpdated":"2017-01-09T01:28:06-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483952154359_987738350","id":"20170109-005554_729378682","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-01-09T00:55:54-0800","dateStarted":"2017-01-09T01:28:06-0800","dateFinished":"2017-01-09T01:28:07-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9975","focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483954157172_-493859098","id":"20170109-012917_291516717","dateCreated":"2017-01-09T01:29:17-0800","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11672","text":"%md\n# Start!","dateUpdated":"2017-01-09T01:29:28-0800","dateFinished":"2017-01-09T01:29:24-0800","dateStarted":"2017-01-09T01:29:24-0800","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Start!</h1>\n"}},{"text":"ssc.start()","dateUpdated":"2017-01-09T01:28:14-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483952215998_986092085","id":"20170109-005655_1237628677","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-01-09T00:56:55-0800","dateStarted":"2017-01-09T01:28:14-0800","dateFinished":"2017-01-09T01:28:14-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9976","focus":true},{"text":"ssc.stop(false)","dateUpdated":"2017-01-09T01:28:25-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483952418244_1594626","id":"20170109-010018_778177279","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-01-09T01:00:18-0800","dateStarted":"2017-01-09T01:28:25-0800","dateFinished":"2017-01-09T01:28:27-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9977","focus":true},{"text":"","dateUpdated":"2017-01-09T01:02:14-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483952515244_-1080933892","id":"20170109-010155_1017767255","dateCreated":"2017-01-09T01:01:55-0800","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:9978"}],"name":"Spark Weather RDD Streaming Solution","id":"2C6CRZ8B5","angularObjects":{"2C7PVCCMW:shared_process":[],"2C7N8FNUK:shared_process":[],"2C4ZABBYG:shared_process":[],"2C7NHPHKH:shared_process":[],"2C4ACPMVH:shared_process":[],"2C5JAXWD8:shared_process":[],"2C68PFPBP:shared_process":[],"2C6BVC9ES:shared_process":[],"2C66FR28V:shared_process":[],"2C4Y5MV3V:shared_process":[],"2C6KQ2GNT:shared_process":[],"2C78K3BRW:shared_process":[],"2C81FGN7P:shared_process":[],"2C5BQGTGT:shared_process":[],"2C7VFSCFR:shared_process":[],"2C5MXJ5D6:shared_process":[],"2C44EB781:shared_process":[],"2C4JS2HDQ:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}