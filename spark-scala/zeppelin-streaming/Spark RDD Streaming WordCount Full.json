{"paragraphs":[{"text":"%md\n# Create a Streaming Context\n\nStreaming is performed using a special StreamingContext, which can be constructed from an existing SparkContext. Additionally a window size for micro batches is required.","dateUpdated":"2017-01-08T23:31:51-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483947042591_-904345061","id":"20170108-233042_1449790585","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Create a Streaming Context</h1>\n<p>Streaming is performed using a special StreamingContext, which can be constructed from an existing SparkContext. Additionally a window size for micro batches is required.</p>\n"},"dateCreated":"2017-01-08T23:30:42-0800","dateStarted":"2017-01-08T23:31:48-0800","dateFinished":"2017-01-08T23:31:49-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:291"},{"text":"import org.apache.spark.streaming.StreamingContext\nimport org.apache.spark.streaming.Seconds\n\nval ssc = new StreamingContext(sc, Seconds(1))","dateUpdated":"2017-01-08T23:44:09-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483946946880_1513462999","id":"20170108-232906_1300339760","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.streaming.StreamingContext\n\nimport org.apache.spark.streaming.Seconds\n\nssc: org.apache.spark.streaming.StreamingContext = org.apache.spark.streaming.StreamingContext@4e6c8bd9\n"},"dateCreated":"2017-01-08T23:29:06-0800","dateStarted":"2017-01-08T23:44:09-0800","dateFinished":"2017-01-08T23:44:10-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:292"},{"text":"%md\n# Connect to a Socket Stream\n\nAs an input stream, we simply read text data line by line from a socket","dateUpdated":"2017-01-08T23:32:33-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483947037039_76364561","id":"20170108-233037_315077291","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Connect to a Socket Stream</h1>\n<p>As an input stream, we simply read text data line by line from a socket</p>\n"},"dateCreated":"2017-01-08T23:30:37-0800","dateStarted":"2017-01-08T23:32:30-0800","dateFinished":"2017-01-08T23:32:30-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:293"},{"text":"val input = ssc.socketTextStream(\"localhost\", 9977)","dateUpdated":"2017-01-08T23:44:12-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483947150297_203083222","id":"20170108-233230_1519381867","result":{"code":"SUCCESS","type":"TEXT","msg":"\ninput: org.apache.spark.streaming.dstream.ReceiverInputDStream[String] = org.apache.spark.streaming.dstream.SocketInputDStream@686df68\n"},"dateCreated":"2017-01-08T23:32:30-0800","dateStarted":"2017-01-08T23:44:12-0800","dateFinished":"2017-01-08T23:44:12-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:294"},{"text":"input.print()","dateUpdated":"2017-01-08T23:44:14-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483947271816_983554850","id":"20170108-233431_2053188651","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-01-08T23:34:31-0800","dateStarted":"2017-01-08T23:44:15-0800","dateFinished":"2017-01-08T23:44:15-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:295"},{"text":"%md\n## Start Execution of SparkStreamingContext\nThis will trigger the action above (input.print) every second.","dateUpdated":"2017-01-08T23:45:08-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483947873470_-812978971","id":"20170108-234433_1599037616","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Start Execution of SparkStreamingContext</h2>\n<p>This will trigger the action above (input.print) every second.</p>\n"},"dateCreated":"2017-01-08T23:44:33-0800","dateStarted":"2017-01-08T23:45:04-0800","dateFinished":"2017-01-08T23:45:04-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:296"},{"text":"ssc.start()","dateUpdated":"2017-01-08T23:44:17-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483947294318_1251740158","id":"20170108-233454_1512277211","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-01-08T23:34:54-0800","dateStarted":"2017-01-08T23:44:17-0800","dateFinished":"2017-01-08T23:44:17-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:297"},{"text":"%md\n## Stop Execution.\nIn order to stop the output, we have to stop the StreamingContext. This will actually render the streaming context invalid. This means that we need to create a new SparkStreamingContext for the next steps.","dateUpdated":"2017-01-08T23:46:13-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483947911394_-1355064980","id":"20170108-234511_818359632","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Stop Execution.</h2>\n<p>In order to stop the output, we have to stop the StreamingContext. This will actually render the streaming context invalid. This means that we need to create a new SparkStreamingContext for the next steps.</p>\n"},"dateCreated":"2017-01-08T23:45:11-0800","dateStarted":"2017-01-08T23:46:11-0800","dateFinished":"2017-01-08T23:46:11-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:298"},{"text":"ssc.stop(false)","dateUpdated":"2017-01-08T23:44:22-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483947356702_345949302","id":"20170108-233556_1618251830","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-01-08T23:35:56-0800","dateStarted":"2017-01-08T23:44:22-0800","dateFinished":"2017-01-08T23:44:23-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:299"},{"text":"%md\n# Streaming WordCount\n\nNow let's start over again with a simple streaming word count example. We need to recreatre a SparkStreamingContext, because the stopped one cannot be reused any more. \n\nTo make things a little bit more interesting, we will also use a sliding window which is 10 seconds large and slides in 3 seconds intervals.","dateUpdated":"2017-01-08T23:51:50-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483947376972_1497700330","id":"20170108-233616_1495710021","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Streaming WordCount</h1>\n<p>Now let's start over again with a simple streaming word count example. We need to recreatre a SparkStreamingContext, because the stopped one cannot be reused any more.</p>\n<p>To make things a little bit more interesting, we will also use a sliding window which is 10 seconds large and slides in 3 seconds intervals.</p>\n"},"dateCreated":"2017-01-08T23:36:16-0800","dateStarted":"2017-01-08T23:51:47-0800","dateFinished":"2017-01-08T23:51:47-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:300"},{"text":"val ssc = new StreamingContext(sc, Seconds(1))\nval input = ssc.socketTextStream(\"localhost\", 9977)\n\ninput.window(Seconds(10), Seconds(3))\n    .flatMap(_.split(\" \"))\n    .filter(_ != \"\")\n    .map(x => (x,1))\n    .reduceByKey(_ + _)\n    .transform(_.sortBy(_._2, ascending = false))\n    .print(20)\n","dateUpdated":"2017-01-08T23:47:20-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483947983140_-1483262985","id":"20170108-234623_1986387111","result":{"code":"SUCCESS","type":"TEXT","msg":"\nssc: org.apache.spark.streaming.StreamingContext = org.apache.spark.streaming.StreamingContext@6976def6\n\ninput: org.apache.spark.streaming.dstream.ReceiverInputDStream[String] = org.apache.spark.streaming.dstream.SocketInputDStream@4afabded\n"},"dateCreated":"2017-01-08T23:46:23-0800","dateStarted":"2017-01-08T23:47:21-0800","dateFinished":"2017-01-08T23:47:23-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:301"},{"text":"ssc.start()","dateUpdated":"2017-01-08T23:47:33-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483948024016_-116573595","id":"20170108-234704_1086216784","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-01-08T23:47:04-0800","dateStarted":"2017-01-08T23:47:33-0800","dateFinished":"2017-01-08T23:47:34-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:302"},{"text":"","dateUpdated":"2017-01-08T23:47:44-0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483948053715_-909694320","id":"20170108-234733_765755999","dateCreated":"2017-01-08T23:47:33-0800","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:303"}],"name":"Spark RDD Streaming WordCount Full","id":"2C8YAHAEZ","angularObjects":{"2C7PVCCMW:shared_process":[],"2C7N8FNUK:shared_process":[],"2C4ZABBYG:shared_process":[],"2C7NHPHKH:shared_process":[],"2C4ACPMVH:shared_process":[],"2C5JAXWD8:shared_process":[],"2C68PFPBP:shared_process":[],"2C6BVC9ES:shared_process":[],"2C66FR28V:shared_process":[],"2C4Y5MV3V:shared_process":[],"2C6KQ2GNT:shared_process":[],"2C78K3BRW:shared_process":[],"2C81FGN7P:shared_process":[],"2C5BQGTGT:shared_process":[],"2C7VFSCFR:shared_process":[],"2C5MXJ5D6:shared_process":[],"2C44EB781:shared_process":[],"2C4JS2HDQ:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}