{"paragraphs":[{"text":"%md\n# Create a Streaming Context\n\nStreaming is performed using a special StreamingContext, which can be constructed from an existing SparkContext. Additionally a window size for micro batches is required.","dateUpdated":"2017-02-18T14:30:49+0000","config":{"colWidth":12,"editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487428249984_-1360366438","id":"20170108-233042_1449790585","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Create a Streaming Context</h1>\n<p>Streaming is performed using a special StreamingContext, which can be constructed from an existing SparkContext. Additionally a window size for micro batches is required.</p>\n"},"dateCreated":"2017-02-18T14:30:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17988"},{"text":"import org.apache.spark.streaming.StreamingContext\nimport org.apache.spark.streaming.Seconds\n\nval ssc = // YOUR CODE HERE","dateUpdated":"2017-02-18T14:31:24+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487428249984_-1360366438","id":"20170108-232906_1300339760","dateCreated":"2017-02-18T14:30:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17989","focus":true},{"text":"%md\n# Connect to a Socket Stream\n\nAs an input stream, we simply read text data line by line from a socket. In order to create the sending stream, you can use the `pynetcat` program as follows\n\n    cat alice-in-wonderland.txt | ./pynetcat.py -I1 -B5 ","dateUpdated":"2017-02-18T14:30:49+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487428249984_-1360366438","id":"20170108-233037_315077291","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Connect to a Socket Stream</h1>\n<p>As an input stream, we simply read text data line by line from a socket. In order to create the sending stream, you can use the <code>pynetcat</code> program as follows</p>\n<pre><code>cat alice-in-wonderland.txt | ./pynetcat.py -I1 -B5\n</code></pre>\n"},"dateCreated":"2017-02-18T14:30:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17990"},{"text":"val master = // YOUR CODE HERE\nval input = // YOUR CODE HERE","dateUpdated":"2017-02-18T14:32:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487428249984_-1360366438","id":"20170108-233230_1519381867","dateCreated":"2017-02-18T14:30:49+0000","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17991","dateFinished":"2017-02-18T14:32:54+0000","dateStarted":"2017-02-18T14:32:47+0000","focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487428366353_184585931","id":"20170218-143246_852432697","dateCreated":"2017-02-18T14:32:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18897","text":"%md\n## Execute Print Action\nFor every RDD received from the stream, we want to print it on the driver side. This can be achieved by attaching a `print` action to the raw stream.","dateUpdated":"2017-02-18T14:32:50+0000","dateFinished":"2017-02-18T14:32:47+0000","dateStarted":"2017-02-18T14:32:47+0000","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Execute Print Action</h2>\n<p>For every RDD received from the stream, we want to print it on the driver side. This can be achieved by attaching a <code>print</code> action to the raw stream.</p>\n"}},{"text":"// YOUR CODE HERE","dateUpdated":"2017-02-18T14:30:49+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487428249984_-1360366438","id":"20170108-233431_2053188651","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-02-18T14:30:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17992"},{"text":"%md\n## Start Execution of SparkStreamingContext\nThis will trigger the action above (input.print) every second.","dateUpdated":"2017-02-18T14:30:49+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487428249984_-1360366438","id":"20170108-234433_1599037616","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Start Execution of SparkStreamingContext</h2>\n<p>This will trigger the action above (input.print) every second.</p>\n"},"dateCreated":"2017-02-18T14:30:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17993"},{"text":"// YOUR CODE HERE","dateUpdated":"2017-02-18T14:30:49+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487428249984_-1360366438","id":"20170108-233454_1512277211","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-02-18T14:30:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17994"},{"text":"%md\n## Stop Execution.\nIn order to stop the output, we have to stop the StreamingContext. This will actually render the streaming context invalid. This means that we need to create a new SparkStreamingContext for the next steps.\n\nYou also can specify if the underlying SparkContext should also be destroyed. Since we do not want this to happen, we explicitly pass `false` as an argument to prevent the SparkContext itself from being stopped.","dateUpdated":"2017-02-18T14:30:49+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487428249984_-1360366438","id":"20170108-234511_818359632","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Stop Execution.</h2>\n<p>In order to stop the output, we have to stop the StreamingContext. This will actually render the streaming context invalid. This means that we need to create a new SparkStreamingContext for the next steps.</p>\n<p>You also can specify if the underlying SparkContext should also be destroyed. Since we do not want this to happen, we explicitly pass <code>false</code> as an argument to prevent the SparkContext itself from being stopped.</p>\n"},"dateCreated":"2017-02-18T14:30:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17995"},{"text":"// YOUR CODE HERE","dateUpdated":"2017-02-18T14:30:49+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487428249984_-1360366438","id":"20170108-233556_1618251830","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-02-18T14:30:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17996"},{"text":"%md\n# Streaming WordCount\n\nNow let's start over again with a simple streaming word count example. We need to recreatre a SparkStreamingContext, because the stopped one cannot be reused any more. \n\nTo make things a little bit more interesting, we will also use a sliding window which is 10 seconds large and slides in 3 seconds intervals.","dateUpdated":"2017-02-18T14:30:49+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487428249984_-1360366438","id":"20170108-233616_1495710021","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Streaming WordCount</h1>\n<p>Now let's start over again with a simple streaming word count example. We need to recreatre a SparkStreamingContext, because the stopped one cannot be reused any more.</p>\n<p>To make things a little bit more interesting, we will also use a sliding window which is 10 seconds large and slides in 3 seconds intervals.</p>\n"},"dateCreated":"2017-02-18T14:30:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17997"},{"text":"val ssc = // YOUR CODE HERE\nval input = // YOUR CODE HERE\n\n// YOUR CODE HERE\n","dateUpdated":"2017-02-18T14:30:49+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487428249984_-1360366438","id":"20170108-234623_1986387111","result":{"code":"SUCCESS","type":"TEXT","msg":"\nssc: org.apache.spark.streaming.StreamingContext = org.apache.spark.streaming.StreamingContext@6976def6\n\ninput: org.apache.spark.streaming.dstream.ReceiverInputDStream[String] = org.apache.spark.streaming.dstream.SocketInputDStream@4afabded\n"},"dateCreated":"2017-02-18T14:30:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17998"},{"text":"ssc.start()","dateUpdated":"2017-02-18T14:30:49+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487428249984_-1360366438","id":"20170108-234704_1086216784","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-02-18T14:30:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17999"},{"text":"ssc.stop(false)","dateUpdated":"2017-02-18T14:30:49+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1487428249984_-1360366438","id":"20170108-234733_765755999","dateCreated":"2017-02-18T14:30:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18000"}],"name":"Spark RDD Streaming - Skeleton","id":"2C9E9EMH6","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}