{"paragraphs":[{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485843454993_-2110918993","id":"20170130-221734_229219199","dateCreated":"2017-01-30T22:17:34-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:197","text":"%md\n# Word Count Revisited\n\nSo lt's recreate a word count for Alice in Wonderland using the Spark RDD API. We need to perform the following steps:\n1. Load the source file as text data using the `textFile` method of the Spark context\n2. Split every line into multiple words\n3. Remove empty words\n4. Add a count of 1 to every word, so the RDD contains tuples `(word,1)`\n5. Sum up the word counts per word in the resulting PairRDD from the previous step\n6. Sort the result in descending order by the word frequencies\n7. Create a nice TSV (tab separated values) representation of every entry `word\\tcount`\n8. Save the result somewhere in HDFS (maybe `/user/zeppelin/alice_counts`) using `saveAsTextFile`","dateUpdated":"2017-01-30T22:22:41-0800","dateFinished":"2017-01-30T22:22:39-0800","dateStarted":"2017-01-30T22:22:39-0800","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Word Count Revisited</h1>\n<p>So lt's recreate a word count for Alice in Wonderland using the Spark RDD API. We need to perform the following steps:</p>\n<ol>\n<li>Load the source file as text data using the <code>textFile</code> method of the Spark context</li>\n<li>Split every line into multiple words</li>\n<li>Remove empty words</li>\n<li>Add a count of 1 to every word, so the RDD contains tuples <code>(word,1)</code></li>\n<li>Sum up the word counts per word in the resulting PairRDD from the previous step</li>\n<li>Sort the result in descending order by the word frequencies</li>\n<li>Create a nice TSV (tab separated values) representation of every entry <code>word\\tcount</code></li>\n<li>Save the result somewhere in HDFS (maybe <code>/user/zeppelin/alice_counts</code>) using <code>saveAsTextFile</code></li>\n</ol>\n"},"focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485843467811_1714067392","id":"20170130-221747_308746184","dateCreated":"2017-01-30T22:17:47-0800","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:359","dateUpdated":"2017-01-30T22:22:48-0800","dateFinished":"2017-01-30T22:18:10-0800","dateStarted":"2017-01-30T22:17:59-0800","errorMessage":"","text":"val text = sc.textFile(\"s3://dimajix-training/data/alice\")\nval words = text.flatMap(_.split(\" \"))\n    .filter(_ != \"\")\n    .map(x => (x,1))\n    .reduceByKey(_ + _)\n    .sortBy(_._2, ascending=false)\n    .map({ case (k,v) => k + '\\t' + v.toString() })\n    \nwords.saveAsTextFile(\"/user/zeppelin/alice_counts\")"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485843490755_195878881","id":"20170130-221810_265200548","dateCreated":"2017-01-30T22:18:10-0800","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:510","text":"%md\n## Let's peek inside the result\nIn order to look into the resulting file in HDFS, we need to resort to the shell tools for HDFS.","dateUpdated":"2017-01-30T22:18:58-0800","dateFinished":"2017-01-30T22:18:56-0800","dateStarted":"2017-01-30T22:18:56-0800","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Let's peek inside the result</h2>\n<p>In order to look into the resulting file in HDFS, we need to resort to the shell tools for HDFS.</p>\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485843479369_614455036","id":"20170130-221759_788343263","dateCreated":"2017-01-30T22:17:59-0800","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:432","dateUpdated":"2017-01-30T22:22:48-0800","text":"%sh\nhdfs dfs -getmerge /user/zeppelin/alice_counts /tmp/alice_counts.txt\ncat /tmp/alice_counts.txt | head -n20\n"}],"name":"Spark RDD WordCount - Full","id":"2CAG9KEMM","angularObjects":{"2C73P7NJN:shared_process":[],"2C7KU6EWG:shared_process":[],"2C8H7AG7Q:shared_process":[],"2CANY5QMM:shared_process":[],"2C7YM9SBT:shared_process":[],"2CAHZM5EW:shared_process":[],"2CA194TC4:shared_process":[],"2C85Z5A3J:shared_process":[],"2C77BBC6M:shared_process":[],"2C9T8R64M:shared_process":[],"2C82H3SUX:shared_process":[],"2C7W1UTSM:shared_process":[],"2C99CAHNC:shared_process":[],"2C7VKNJZ3:shared_process":[],"2C7MNAP62:shared_process":[],"2C8SJ4SC1:shared_process":[],"2C8273BS9:shared_process":[],"2CA9V89Q3:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}