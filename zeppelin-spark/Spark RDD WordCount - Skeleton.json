{"paragraphs":[{"text":"%md\n# Word Count Revisited\n\nSo lt's recreate a word count for Alice in Wonderland using the Spark RDD API. We need to perform the following steps:\n1. Load the source file as text data using the `textFile` method of the Spark context\n2. Split every line into multiple words\n3. Remove empty words\n4. Add a count of 1 to every word, so the RDD contains tuples `(word,1)`\n5. Sum up the word counts per word in the resulting PairRDD from the previous step\n6. Sort the result in descending order by the word frequencies\n7. Create a nice TSV (tab separated values) representation of every entry `word\\tcount`\n8. Save the result somewhere in HDFS (maybe `/user/zeppelin/alice_counts`) using `saveAsTextFile`","dateUpdated":"2017-01-30T22:24:28-0800","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485843868573_-350114269","id":"20170130-221734_229219199","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Word Count Revisited</h1>\n<p>So lt's recreate a word count for Alice in Wonderland using the Spark RDD API. We need to perform the following steps:</p>\n<ol>\n<li>Load the source file as text data using the <code>textFile</code> method of the Spark context</li>\n<li>Split every line into multiple words</li>\n<li>Remove empty words</li>\n<li>Add a count of 1 to every word, so the RDD contains tuples <code>(word,1)</code></li>\n<li>Sum up the word counts per word in the resulting PairRDD from the previous step</li>\n<li>Sort the result in descending order by the word frequencies</li>\n<li>Create a nice TSV (tab separated values) representation of every entry <code>word\\tcount</code></li>\n<li>Save the result somewhere in HDFS (maybe <code>/user/zeppelin/alice_counts</code>) using <code>saveAsTextFile</code></li>\n</ol>\n"},"dateCreated":"2017-01-30T22:24:28-0800","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:738"},{"text":"val text = sc.textFile(\"s3://dimajix-training/data/alice\")\n// YOUR CODE HERE","dateUpdated":"2017-01-30T22:24:28-0800","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"colWidth":12,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485843868573_-350114269","id":"20170130-221747_308746184","dateCreated":"2017-01-30T22:24:28-0800","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:739"},{"text":"%md\n## Let's peek inside the result\nIn order to look into the resulting file in HDFS, we need to resort to the shell tools for HDFS.","dateUpdated":"2017-01-30T22:24:28-0800","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485843868574_-348960022","id":"20170130-221810_265200548","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Let's peek inside the result</h2>\n<p>In order to look into the resulting file in HDFS, we need to resort to the shell tools for HDFS.</p>\n"},"dateCreated":"2017-01-30T22:24:28-0800","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:740"},{"text":"%sh\nhdfs dfs -getmerge /user/zeppelin/alice_counts /tmp/alice_counts.txt\ncat /tmp/alice_counts.txt | head -n20\n","dateUpdated":"2017-01-30T22:24:28-0800","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"colWidth":12,"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485843868574_-348960022","id":"20170130-221759_788343263","dateCreated":"2017-01-30T22:24:28-0800","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:741"}],"name":"Spark RDD WordCount - Skeleton","id":"2C8T4QF78","angularObjects":{"2C73P7NJN:shared_process":[],"2C7KU6EWG:shared_process":[],"2C8H7AG7Q:shared_process":[],"2CANY5QMM:shared_process":[],"2C7YM9SBT:shared_process":[],"2CAHZM5EW:shared_process":[],"2CA194TC4:shared_process":[],"2C85Z5A3J:shared_process":[],"2C77BBC6M:shared_process":[],"2C9T8R64M:shared_process":[],"2C82H3SUX:shared_process":[],"2C7W1UTSM:shared_process":[],"2C99CAHNC:shared_process":[],"2C7VKNJZ3:shared_process":[],"2C7MNAP62:shared_process":[],"2C8SJ4SC1:shared_process":[],"2C8273BS9:shared_process":[],"2CA9V89Q3:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}