{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repartitioning Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "storageLocation = \"s3://dimajix-training/data/weather\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from functools import reduce\n",
    "\n",
    "# Read in all years, store them in an Python array\n",
    "raw_weather_per_year = [spark.read.text(storageLocation + \"/\" + str(i)).withColumn(\"year\", lit(i)) for i in range(2003,2015)]\n",
    "\n",
    "# Union all years together\n",
    "raw_weather = reduce(lambda l,r: l.union(r), raw_weather_per_year)                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a single year to keep execution plans small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_weather = spark.read.text(storageLocation + \"/2003\").withColumn(\"year\", lit(2003))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = raw_weather.select(\n",
    "    col(\"year\"),\n",
    "    substring(col(\"value\"),5,6).alias(\"usaf\"),\n",
    "    substring(col(\"value\"),11,5).alias(\"wban\"),\n",
    "    substring(col(\"value\"),16,8).alias(\"date\"),\n",
    "    substring(col(\"value\"),24,4).alias(\"time\"),\n",
    "    substring(col(\"value\"),42,5).alias(\"report_type\"),\n",
    "    substring(col(\"value\"),61,3).alias(\"wind_direction\"),\n",
    "    substring(col(\"value\"),64,1).alias(\"wind_direction_qual\"),\n",
    "    substring(col(\"value\"),65,1).alias(\"wind_observation\"),\n",
    "    (substring(col(\"value\"),66,4).cast(\"float\") / lit(10.0)).alias(\"wind_speed\"),\n",
    "    substring(col(\"value\"),70,1).alias(\"wind_speed_qual\"),\n",
    "    (substring(col(\"value\"),88,5).cast(\"float\") / lit(10.0)).alias(\"air_temperature\"),\n",
    "    substring(col(\"value\"),93,1).alias(\"air_temperature_qual\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load Station Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(storageLocation + \"/isd-history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Repartitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [usaf#87, wban#88], [usaf#122, wban#123], Inner, BuildRight\n",
      ":- *(2) Project [2003 AS year#84, substring(value#82, 5, 6) AS usaf#87, substring(value#82, 11, 5) AS wban#88, substring(value#82, 16, 8) AS date#89, substring(value#82, 24, 4) AS time#90, substring(value#82, 42, 5) AS report_type#91, substring(value#82, 61, 3) AS wind_direction#92, substring(value#82, 64, 1) AS wind_direction_qual#93, substring(value#82, 65, 1) AS wind_observation#94, (cast(cast(substring(value#82, 66, 4) as float) as double) / 10.0) AS wind_speed#95, substring(value#82, 70, 1) AS wind_speed_qual#96, (cast(cast(substring(value#82, 88, 5) as float) as double) / 10.0) AS air_temperature#97, substring(value#82, 93, 1) AS air_temperature_qual#98]\n",
      ":  +- *(2) Filter (isnotnull(substring(value#82, 5, 6)) && isnotnull(substring(value#82, 11, 5)))\n",
      ":     +- *(2) FileScan text [value#82] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true], input[1, string, true]))\n",
      "   +- *(1) Project [USAF#122, WBAN#123, STATION NAME#124, CTRY#125, STATE#126, ICAO#127, LAT#128, LON#129, ELEV(M)#130, BEGIN#131, END#132]\n",
      "      +- *(1) Filter (isnotnull(usaf#122) && isnotnull(wban#123))\n",
      "         +- *(1) FileScan csv [USAF#122,WBAN#123,STATION NAME#124,CTRY#125,STATE#126,ICAO#127,LAT#128,LON#129,ELEV(M)#130,BEGIN#131,END#132] Batched: false, Format: CSV, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/isd-history], PartitionFilters: [], PushedFilters: [IsNotNull(USAF), IsNotNull(WBAN)], ReadSchema: struct<USAF:string,WBAN:string,STATION NAME:string,CTRY:string,STATE:string,ICAO:string,LAT:strin...\n"
     ]
    }
   ],
   "source": [
    "result = weather.join(stations, (weather[\"usaf\"] == stations[\"usaf\"]) & (weather[\"wban\"] == stations[\"wban\"]))\n",
    "result.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 2.3 (Python 3)",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
