{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "First we load data from HDFS. It is stored as a trivial CSV file with three columns\n",
    "1. product name\n",
    "2. review text\n",
    "3. rating (1 - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>This was the only calender I could find for th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I completed a calendar for my son's first year...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              name  \\\n",
       "0                            Planetwise Wipe Pouch   \n",
       "1              Annas Dream Full Quilt with 2 Shams   \n",
       "2  Nature's Lullabies Second Year Sticker Calendar   \n",
       "3  Nature's Lullabies Second Year Sticker Calendar   \n",
       "4  Nature's Lullabies Second Year Sticker Calendar   \n",
       "\n",
       "                                              review  rating  \n",
       "0  it came early and was not disappointed. i love...       5  \n",
       "1  Very soft and comfortable and warmer than it l...       5  \n",
       "2  This was the only calender I could find for th...       5  \n",
       "3  I completed a calendar for my son's first year...       4  \n",
       "4  We wanted to get something to keep track of ou...       5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "data = sqlContext.read.text(\"/user/cloudera/data/amazon_baby\")\n",
    "data = data.select(\n",
    "        split('value',',')[0].alias('name'),\n",
    "        split('value',',')[1].alias('review'),\n",
    "        split('value',',')[2].alias('rating').cast('int')\n",
    ").filter(col('rating').isNotNull())\n",
    "\n",
    "data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train Data / Test Data\n",
    "\n",
    "Now let's do the usual split of our data into a training data set and a validation data set. Let's use 80% of all reviews for training and 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: 25613\n",
      "test_data: 6497\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = data.randomSplit([0.8,0.2], seed=1)\n",
    "\n",
    "print \"train_data: %d\" % train_data.count()\n",
    "print \"test_data: %d\" % test_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Transformer\n",
    "\n",
    "We need a custom Transformer to build the pipeline. The transformer should remove all punctuations from a given column containing text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    import string\n",
    "    for c in string.punctuation:\n",
    "        text = text.replace(c, ' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "class PunctuationCleanupTransformer(Transformer):\n",
    "    def __init__(self, inputCol, outputCol):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.inputCol = inputCol\n",
    "        self.outputCol = outputCol\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        remove_punctuation_udf = udf(remove_punctuations, StringType())\n",
    "        return dataset.withColumn(self.outputCol, remove_punctuation_udf(self.inputCol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Transformer\n",
    "\n",
    "Lets create an instance of the Transformer and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed  i love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>This was the only calender I could find for th...</td>\n",
       "      <td>5</td>\n",
       "      <td>This was the only calender I could find for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I completed a calendar for my son's first year...</td>\n",
       "      <td>4</td>\n",
       "      <td>I completed a calendar for my son s first year...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              name  \\\n",
       "0                            Planetwise Wipe Pouch   \n",
       "1              Annas Dream Full Quilt with 2 Shams   \n",
       "2  Nature's Lullabies Second Year Sticker Calendar   \n",
       "3  Nature's Lullabies Second Year Sticker Calendar   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  it came early and was not disappointed. i love...       5   \n",
       "1  Very soft and comfortable and warmer than it l...       5   \n",
       "2  This was the only calender I could find for th...       5   \n",
       "3  I completed a calendar for my son's first year...       4   \n",
       "\n",
       "                                        clean_review  \n",
       "0  it came early and was not disappointed  i love...  \n",
       "1  Very soft and comfortable and warmer than it l...  \n",
       "2  This was the only calender I could find for th...  \n",
       "3  I completed a calendar for my son s first year...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner = PunctuationCleanupTransformer(inputCol='review', outputCol='clean_review')\n",
    "clean_data = cleaner.transform(data)\n",
    "\n",
    "clean_data.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ML Pipeline\n",
    "\n",
    "Now we have all components for creating an initial ML Pipeline. Remember that we have been using the following components before\n",
    "\n",
    "* Tokenizer - for splitting reviews into words\n",
    "* StopWordRemover - for removing stop words\n",
    "* CountVectorizer - for creating bag-of-word features from the words\n",
    "* LogisticRegression - for creating the real model\n",
    "\n",
    "You also need to transform the incoming rating (1-5) to a sentiment (0 or 1) and you need to drop reviews with a rating of 3. This can be done using one ore more SQLTransformer instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.classification import *\n",
    "\n",
    "stopWords=['the','a','and','or', 'it', 'this', 'of', 'an', 'as', 'in', 'on', 'is', 'are', 'to', 'was', 'for', 'then', 'i']\n",
    "\n",
    "stages = [\n",
    "    PunctuationCleanupTransformer(inputCol='review', outputCol='clean_review'),\n",
    "    SQLTransformer(statement='SELECT *,CASE WHEN rating < 3 THEN 0.0 ELSE 1.0 END AS sentiment FROM __THIS__ WHERE rating <> 3'),\n",
    "    Tokenizer(inputCol='clean_review', outputCol='words'),\n",
    "    StopWordsRemover(inputCol='words', outputCol='vwords', stopWords=stopWords),\n",
    "    CountVectorizer(inputCol='vwords', outputCol='features', minDF=2.0),\n",
    "    LogisticRegression(featuresCol='features',labelCol='sentiment')\n",
    "]\n",
    "pipe = Pipeline(stages = stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Pipeline Model\n",
    "Using training data, we create a PipelineModel by fitting the Pipeline to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pipe.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Data\n",
    "\n",
    "Let us do some predictions of the test data using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/python/pyspark/ml/classification.py:207: UserWarning: weights is deprecated. Use coefficients instead.\n",
      "  warnings.warn(\"weights is deprecated. Use coefficients instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>words</th>\n",
       "      <th>vwords</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>I don't understand some of the high reviews fo...</td>\n",
       "      <td>1</td>\n",
       "      <td>I don t understand some of the high reviews fo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[i, don, t, understand, some, of, the, high, r...</td>\n",
       "      <td>[don, t, understand, some, high, reviews, item...</td>\n",
       "      <td>(15.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 4.0,...</td>\n",
       "      <td>[5.1398939764, -5.1398939764]</td>\n",
       "      <td>[0.994175809121, 0.00582419087928]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>I'm all for being 'green'; this bag is perfect...</td>\n",
       "      <td>5</td>\n",
       "      <td>I m all for being  green   this bag is perfect...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, m, all, for, being, , green, , , this, bag...</td>\n",
       "      <td>[m, all, being, , green, , , bag, perfect, hol...</td>\n",
       "      <td>(6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-2.38193431757, 2.38193431757]</td>\n",
       "      <td>[0.0845607094526, 0.915439290547]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>My youngest son is now 16 months old but we ha...</td>\n",
       "      <td>5</td>\n",
       "      <td>My youngest son is now 16 months old but we ha...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[my, youngest, son, is, now, 16, months, old, ...</td>\n",
       "      <td>[my, youngest, son, now, 16, months, old, but,...</td>\n",
       "      <td>(3.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-3.83209868013, 3.83209868013]</td>\n",
       "      <td>[0.0212047206389, 0.978795279361]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>This blanket goes perfectly in our future litt...</td>\n",
       "      <td>4</td>\n",
       "      <td>This blanket goes perfectly in our future litt...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[this, blanket, goes, perfectly, in, our, futu...</td>\n",
       "      <td>[blanket, goes, perfectly, our, future, little...</td>\n",
       "      <td>(2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-3.45763126954, 3.45763126954]</td>\n",
       "      <td>[0.0305420917109, 0.969457908289]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>This necklace is very light weight and has rea...</td>\n",
       "      <td>5</td>\n",
       "      <td>This necklace is very light weight and has rea...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[this, necklace, is, very, light, weight, and,...</td>\n",
       "      <td>[necklace, very, light, weight, has, really, h...</td>\n",
       "      <td>(1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-3.39360763737, 3.39360763737]</td>\n",
       "      <td>[0.0324958401926, 0.967504159807]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>does not come with pole that attaches to crib ...</td>\n",
       "      <td>1</td>\n",
       "      <td>does not come with pole that attaches to crib ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[does, not, come, with, pole, that, attaches, ...</td>\n",
       "      <td>[does, not, come, with, pole, that, attaches, ...</td>\n",
       "      <td>(0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.502370008844, -0.502370008844]</td>\n",
       "      <td>[0.623016130218, 0.376983869782]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&amp;quot;A Little Pillow Company&amp;quot; Hypoallerg...</td>\n",
       "      <td>I purchased this pillow for my 2 1/2 yr old on...</td>\n",
       "      <td>5</td>\n",
       "      <td>I purchased this pillow for my 2 1 2 yr old on...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, purchased, this, pillow, for, my, 2, 1, 2,...</td>\n",
       "      <td>[purchased, pillow, my, 2, 1, 2, yr, old, once...</td>\n",
       "      <td>(7.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>[-6.72779333296, 6.72779333296]</td>\n",
       "      <td>[0.00119574029854, 0.998804259701]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&amp;quot;A Little Pillow Company&amp;quot; Hypoallerg...</td>\n",
       "      <td>If this pillow were any larger I would worry a...</td>\n",
       "      <td>4</td>\n",
       "      <td>If this pillow were any larger I would worry a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[if, this, pillow, were, any, larger, i, would...</td>\n",
       "      <td>[if, pillow, were, any, larger, would, worry, ...</td>\n",
       "      <td>(3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-3.38684333301, 3.38684333301]</td>\n",
       "      <td>[0.0327091828269, 0.967290817173]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&amp;quot;A Little Pillow Company&amp;quot; Hypoallerg...</td>\n",
       "      <td>This is just perfect size for a little toddler...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is just perfect size for a little toddler...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[this, is, just, perfect, size, for, a, little...</td>\n",
       "      <td>[just, perfect, size, little, toddler, , s, so...</td>\n",
       "      <td>(2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-3.37929013603, 3.37929013603]</td>\n",
       "      <td>[0.0329490059584, 0.967050994042]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&amp;quot;B&amp;quot; Is for Babies (And Booties!) 201...</td>\n",
       "      <td>Exactly what I was looking for! These are porc...</td>\n",
       "      <td>5</td>\n",
       "      <td>Exactly what I was looking for  These are porc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[exactly, what, i, was, looking, for, , these,...</td>\n",
       "      <td>[exactly, what, looking, , these, porcelain, ,...</td>\n",
       "      <td>(4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-1.16730279952, 1.16730279952]</td>\n",
       "      <td>[0.237342861917, 0.762657138083]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "5                                                      \n",
       "6  &quot;A Little Pillow Company&quot; Hypoallerg...   \n",
       "7  &quot;A Little Pillow Company&quot; Hypoallerg...   \n",
       "8  &quot;A Little Pillow Company&quot; Hypoallerg...   \n",
       "9  &quot;B&quot; Is for Babies (And Booties!) 201...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  I don't understand some of the high reviews fo...       1   \n",
       "1  I'm all for being 'green'; this bag is perfect...       5   \n",
       "2  My youngest son is now 16 months old but we ha...       5   \n",
       "3  This blanket goes perfectly in our future litt...       4   \n",
       "4  This necklace is very light weight and has rea...       5   \n",
       "5  does not come with pole that attaches to crib ...       1   \n",
       "6  I purchased this pillow for my 2 1/2 yr old on...       5   \n",
       "7  If this pillow were any larger I would worry a...       4   \n",
       "8  This is just perfect size for a little toddler...       5   \n",
       "9  Exactly what I was looking for! These are porc...       5   \n",
       "\n",
       "                                        clean_review  sentiment  \\\n",
       "0  I don t understand some of the high reviews fo...        0.0   \n",
       "1  I m all for being  green   this bag is perfect...        1.0   \n",
       "2  My youngest son is now 16 months old but we ha...        1.0   \n",
       "3  This blanket goes perfectly in our future litt...        1.0   \n",
       "4  This necklace is very light weight and has rea...        1.0   \n",
       "5  does not come with pole that attaches to crib ...        0.0   \n",
       "6  I purchased this pillow for my 2 1 2 yr old on...        1.0   \n",
       "7  If this pillow were any larger I would worry a...        1.0   \n",
       "8  This is just perfect size for a little toddler...        1.0   \n",
       "9  Exactly what I was looking for  These are porc...        1.0   \n",
       "\n",
       "                                               words  \\\n",
       "0  [i, don, t, understand, some, of, the, high, r...   \n",
       "1  [i, m, all, for, being, , green, , , this, bag...   \n",
       "2  [my, youngest, son, is, now, 16, months, old, ...   \n",
       "3  [this, blanket, goes, perfectly, in, our, futu...   \n",
       "4  [this, necklace, is, very, light, weight, and,...   \n",
       "5  [does, not, come, with, pole, that, attaches, ...   \n",
       "6  [i, purchased, this, pillow, for, my, 2, 1, 2,...   \n",
       "7  [if, this, pillow, were, any, larger, i, would...   \n",
       "8  [this, is, just, perfect, size, for, a, little...   \n",
       "9  [exactly, what, i, was, looking, for, , these,...   \n",
       "\n",
       "                                              vwords  \\\n",
       "0  [don, t, understand, some, high, reviews, item...   \n",
       "1  [m, all, being, , green, , , bag, perfect, hol...   \n",
       "2  [my, youngest, son, now, 16, months, old, but,...   \n",
       "3  [blanket, goes, perfectly, our, future, little...   \n",
       "4  [necklace, very, light, weight, has, really, h...   \n",
       "5  [does, not, come, with, pole, that, attaches, ...   \n",
       "6  [purchased, pillow, my, 2, 1, 2, yr, old, once...   \n",
       "7  [if, pillow, were, any, larger, would, worry, ...   \n",
       "8  [just, perfect, size, little, toddler, , s, so...   \n",
       "9  [exactly, what, looking, , these, porcelain, ,...   \n",
       "\n",
       "                                            features  \\\n",
       "0  (15.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 4.0,...   \n",
       "1  (6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (3.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "3  (2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "4  (1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  (0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "6  (7.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, ...   \n",
       "7  (3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  (2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...   \n",
       "9  (4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                       rawPrediction                         probability  \\\n",
       "0      [5.1398939764, -5.1398939764]  [0.994175809121, 0.00582419087928]   \n",
       "1    [-2.38193431757, 2.38193431757]   [0.0845607094526, 0.915439290547]   \n",
       "2    [-3.83209868013, 3.83209868013]   [0.0212047206389, 0.978795279361]   \n",
       "3    [-3.45763126954, 3.45763126954]   [0.0305420917109, 0.969457908289]   \n",
       "4    [-3.39360763737, 3.39360763737]   [0.0324958401926, 0.967504159807]   \n",
       "5  [0.502370008844, -0.502370008844]    [0.623016130218, 0.376983869782]   \n",
       "6    [-6.72779333296, 6.72779333296]  [0.00119574029854, 0.998804259701]   \n",
       "7    [-3.38684333301, 3.38684333301]   [0.0327091828269, 0.967290817173]   \n",
       "8    [-3.37929013603, 3.37929013603]   [0.0329490059584, 0.967050994042]   \n",
       "9    [-1.16730279952, 1.16730279952]    [0.237342861917, 0.762657138083]   \n",
       "\n",
       "   prediction  \n",
       "0         0.0  \n",
       "1         1.0  \n",
       "2         1.0  \n",
       "3         1.0  \n",
       "4         1.0  \n",
       "5         0.0  \n",
       "6         1.0  \n",
       "7         1.0  \n",
       "8         1.0  \n",
       "9         1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.transform(test_data)\n",
    "\n",
    "pred.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "As in the original exercise, we want to use a custom metric for assessing the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import *\n",
    "\n",
    "class AccuracyClassificationEvaluator(Evaluator):\n",
    "    def __init__(self, predictionCol='prediction', labelCol='label'):\n",
    "        super(Evaluator,self).__init__()\n",
    "        self.predictionCol = predictionCol\n",
    "        self.labelCol = labelCol\n",
    "    \n",
    "    def _evaluate(self, dataset):\n",
    "        num_total = dataset.count()\n",
    "        num_correct = dataset.filter(col(self.labelCol) == col(self.predictionCol)).count()\n",
    "        accuracy = float(num_correct) / num_total\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Performance\n",
    "\n",
    "With the evaluator we can assess the performance of the prediction and easily compare it to a simple model which always predicts 'positive'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 0.910344\n",
      "Baseline Accuracy = 0.848580\n"
     ]
    }
   ],
   "source": [
    "always_positive = pred.withColumn('prediction',lit(1.0))\n",
    "\n",
    "evaluator = AccuracyClassificationEvaluator(predictionCol='prediction', labelCol='sentiment')\n",
    "\n",
    "print \"Model Accuracy = %f\" % evaluator.evaluate(pred)\n",
    "print \"Baseline Accuracy = %f\" % evaluator.evaluate(always_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning\n",
    "\n",
    "Again we want to tune some hyper parameters, but this time inside a pipeline. The methodology is the same as before, we can directly include the CrossValidator into the pipeline. But step by step...\n",
    "\n",
    "First let us have a look at all paremeters of a LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n",
      "featuresCol: features column name. (default: features)\n",
      "fitIntercept: whether to fit an intercept term. (default: True)\n",
      "labelCol: label column name. (default: label)\n",
      "maxIter: max number of iterations (>= 0). (default: 100)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\n",
      "rawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\n",
      "regParam: regularization parameter (>= 0). (default: 0.1)\n",
      "standardization: whether to standardize the training features before fitting the model. (default: True)\n",
      "threshold: Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match. (default: 0.5)\n",
      "thresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values >= 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class' threshold. (undefined)\n",
      "tol: the convergence tolerance for iterative algorithms. (default: 1e-06)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "print LogisticRegression().explainParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ParamGrid\n",
    "\n",
    "Now we create a param grid that should be used for using different sets of parameters. We want to tweak two parameters again:\n",
    "\n",
    "* regParam should take values in [0.0, 0.0001, 0.01, 1.0, 100.0]\n",
    "* maxIter should take values in [10, 100])\n",
    "\n",
    "In order to create this grid, we first need to create an instance of a LogisticRegression, so we can access its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import *\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features',labelCol='sentiment')\n",
    "\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.0, 0.0001, 0.01, 1.0, 100.0]) \\\n",
    "    .addGrid(lr.maxIter, [10, 100]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline\n",
    "\n",
    "Now we can create a pipeline using a CrossValidator instead of directly using a LogisticRegression. This means the configuration of the Pipeline should match the old one except that a CrossValidator is inserted instead of the LogisticRegression. The CrossValidator works as a wrapper of the regression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = AccuracyClassificationEvaluator(labelCol='sentiment')\n",
    "\n",
    "stopWords=['the','a','and','or', 'it', 'this', 'of', 'an', 'as', 'in', 'on', 'is', 'are', 'to', 'was', 'for', 'then', 'i']\n",
    "\n",
    "stages = [\n",
    "    TextCleanupTransformer(inputCol='review', outputCol='clean_review'),\n",
    "    SQLTransformer(statement='SELECT *,CASE WHEN rating < 3 THEN 0.0 ELSE 1.0 END AS sentiment FROM __THIS__ WHERE rating <> 3'),\n",
    "    Tokenizer(inputCol='clean_review', outputCol='words'),\n",
    "    StopWordsRemover(inputCol='words', outputCol='vwords', stopWords=stopWords),\n",
    "    CountVectorizer(inputCol='vwords', outputCol='features', minDF=2.0),\n",
    "    CrossValidator(estimator=lr, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "]\n",
    "\n",
    "pipe = Pipeline(stages = stages)\n",
    "\n",
    "# Fit model to pipeline\n",
    "model = pipe.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 0.921302\n",
      "Baseline Accuracy = 0.848580\n"
     ]
    }
   ],
   "source": [
    "# Predict sentiment for test data\n",
    "pred = model.transform(test_data)\n",
    "\n",
    "print \"Model Accuracy = %f\" % evaluator.evaluate(pred)\n",
    "print \"Baseline Accuracy = %f\" % evaluator.evaluate(always_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
