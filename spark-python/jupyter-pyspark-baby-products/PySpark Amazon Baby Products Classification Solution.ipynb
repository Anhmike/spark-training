{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "First we load data from HDFS. It is stored as a trivial CSV file with three columns\n",
    "1. product name\n",
    "2. review text\n",
    "3. rating (1 - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SoHo Bug's Party Baby Crib Nursery Bedding Set...</td>\n",
       "      <td>We purchased this bedding because we loved the...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...</td>\n",
       "      <td>this 0-3 mos gown is precious but it is signif...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...</td>\n",
       "      <td>Fit nicely with a little room to grow.  VERY S...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...</td>\n",
       "      <td>I bought this for my sister who is doing koala...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Medela Symphony &amp;amp; Lactina Double Pumping K...</td>\n",
       "      <td>Waste waste waste! Manual part sucked also.......</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  SoHo Bug's Party Baby Crib Nursery Bedding Set...   \n",
       "1  Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...   \n",
       "2  Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...   \n",
       "3  Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...   \n",
       "4  Medela Symphony &amp; Lactina Double Pumping K...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  We purchased this bedding because we loved the...       5  \n",
       "1  this 0-3 mos gown is precious but it is signif...       3  \n",
       "2  Fit nicely with a little room to grow.  VERY S...       5  \n",
       "3  I bought this for my sister who is doing koala...       5  \n",
       "4  Waste waste waste! Manual part sucked also.......       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "data = sqlContext.read.text(\"s3://dimajix-training/data/amazon_baby\")\n",
    "data = data.select(\n",
    "        split('value',',')[0].alias('name'),\n",
    "        split('value',',')[1].alias('review'),\n",
    "        split('value',',')[2].alias('rating').cast('int')\n",
    ").filter(col('rating').isNotNull())\n",
    "\n",
    "data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Sentiment\n",
    "\n",
    "Since we want to perform a classification (positive review vs negative review), we need to extract a binary sentiment value. We will map the ratings as follows:\n",
    "\n",
    "1. Ratings 1 and 2 count as a negative review\n",
    "2. Rating 3 counts as a neutral review\n",
    "3. Ratings 4 and 5 count as a positive review\n",
    "\n",
    "Since we want a binary classification, we will also remove neutral reviews altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SoHo Bug's Party Baby Crib Nursery Bedding Set...</td>\n",
       "      <td>We purchased this bedding because we loved the...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...</td>\n",
       "      <td>Fit nicely with a little room to grow.  VERY S...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...</td>\n",
       "      <td>I bought this for my sister who is doing koala...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Medela Symphony &amp;amp; Lactina Double Pumping K...</td>\n",
       "      <td>Waste waste waste! Manual part sucked also.......</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Medela Symphony &amp;amp; Lactina Double Pumping K...</td>\n",
       "      <td>I bought this pumping kit for a Lactina Select...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trend Lab Dr Seuss ABC Framed Receiving Blanket</td>\n",
       "      <td>Very soft little blanket. all of the Dr.Seuss ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Infant Airplane Seat - Flyebaby Airplane Baby ...</td>\n",
       "      <td>Never got to use it!!! It should have come wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Infant Airplane Seat - Flyebaby Airplane Baby ...</td>\n",
       "      <td>Turns airline seat into car seat.  Used on a U...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Infant Airplane Seat - Flyebaby Airplane Baby ...</td>\n",
       "      <td>I mine as well pull out my lighter and burn $5...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Infant Airplane Seat - Flyebaby Airplane Baby ...</td>\n",
       "      <td>Like some of the other reviews mention- the Fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  SoHo Bug's Party Baby Crib Nursery Bedding Set...   \n",
       "1  Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...   \n",
       "2  Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...   \n",
       "3  Medela Symphony &amp; Lactina Double Pumping K...   \n",
       "4  Medela Symphony &amp; Lactina Double Pumping K...   \n",
       "5    Trend Lab Dr Seuss ABC Framed Receiving Blanket   \n",
       "6  Infant Airplane Seat - Flyebaby Airplane Baby ...   \n",
       "7  Infant Airplane Seat - Flyebaby Airplane Baby ...   \n",
       "8  Infant Airplane Seat - Flyebaby Airplane Baby ...   \n",
       "9  Infant Airplane Seat - Flyebaby Airplane Baby ...   \n",
       "\n",
       "                                              review  rating  sentiment  \n",
       "0  We purchased this bedding because we loved the...       5        1.0  \n",
       "1  Fit nicely with a little room to grow.  VERY S...       5        1.0  \n",
       "2  I bought this for my sister who is doing koala...       5        1.0  \n",
       "3  Waste waste waste! Manual part sucked also.......       1        0.0  \n",
       "4  I bought this pumping kit for a Lactina Select...       5        1.0  \n",
       "5  Very soft little blanket. all of the Dr.Seuss ...       4        1.0  \n",
       "6  Never got to use it!!! It should have come wit...       1        0.0  \n",
       "7  Turns airline seat into car seat.  Used on a U...       5        1.0  \n",
       "8  I mine as well pull out my lighter and burn $5...       1        0.0  \n",
       "9  Like some of the other reviews mention- the Fl...       5        1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.filter(data.rating != 3)\n",
    "data = data.withColumn('sentiment', when(data.rating < 3, 0.0).otherwise(1.0))\n",
    "\n",
    "data.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features from Reviews\n",
    "\n",
    "Now we want to split the review text into individual words, so we can create a \"bag of words\" model. In order to get a somewhat nice model, we also need to remove all punctuations from the reviews. This will be done as the first step using a user defined function (UDF) in PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def cleanup_text(text):\n",
    "    for c in string.punctuation:\n",
    "        text = text.replace(c, ' ')\n",
    "    return text\n",
    "\n",
    "remove_punctuation = udf(cleanup_text, StringType())\n",
    "data2 = data.withColumn('review',remove_punctuation('review'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Reviews into Words\n",
    "We could do that ourselves using the Python split method, but we use a Transformer provided by PySpark instead. Saves us some time and helps to create clean code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SoHo Bug's Party Baby Crib Nursery Bedding Set...</td>\n",
       "      <td>We purchased this bedding because we loved the...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[we, purchased, this, bedding, because, we, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...</td>\n",
       "      <td>Fit nicely with a little room to grow   VERY S...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[fit, nicely, with, a, little, room, to, grow,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...</td>\n",
       "      <td>I bought this for my sister who is doing koala...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, bought, this, for, my, sister, who, is, do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  SoHo Bug's Party Baby Crib Nursery Bedding Set...   \n",
       "1  Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...   \n",
       "2  Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  We purchased this bedding because we loved the...       5        1.0   \n",
       "1  Fit nicely with a little room to grow   VERY S...       5        1.0   \n",
       "2  I bought this for my sister who is doing koala...       5        1.0   \n",
       "\n",
       "                                               words  \n",
       "0  [we, purchased, this, bedding, because, we, lo...  \n",
       "1  [fit, nicely, with, a, little, room, to, grow,...  \n",
       "2  [i, bought, this, for, my, sister, who, is, do...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import *\n",
    "\n",
    "tokenizer = Tokenizer(inputCol='review', outputCol='words')\n",
    "words = tokenizer.transform(data2)\n",
    "\n",
    "words.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop words\n",
    "\n",
    "We also want to remove so called stop words, which are all those tiny words which mainly serve as glue for building sentences. Usually they do not contain much information in a simple bag of words model. So we get rid of them.\n",
    "\n",
    "This is so common practice that PySpark already contains a Transformer for just doing that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>words</th>\n",
       "      <th>vwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SoHo Bug's Party Baby Crib Nursery Bedding Set...</td>\n",
       "      <td>We purchased this bedding because we loved the...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[we, purchased, this, bedding, because, we, lo...</td>\n",
       "      <td>[we, purchased, bedding, because, we, loved, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...</td>\n",
       "      <td>Fit nicely with a little room to grow   VERY S...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[fit, nicely, with, a, little, room, to, grow,...</td>\n",
       "      <td>[fit, nicely, with, little, room, grow, , , ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...</td>\n",
       "      <td>I bought this for my sister who is doing koala...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, bought, this, for, my, sister, who, is, do...</td>\n",
       "      <td>[bought, my, sister, who, doing, koalas, her, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  SoHo Bug's Party Baby Crib Nursery Bedding Set...   \n",
       "1  Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...   \n",
       "2  Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  We purchased this bedding because we loved the...       5        1.0   \n",
       "1  Fit nicely with a little room to grow   VERY S...       5        1.0   \n",
       "2  I bought this for my sister who is doing koala...       5        1.0   \n",
       "\n",
       "                                               words  \\\n",
       "0  [we, purchased, this, bedding, because, we, lo...   \n",
       "1  [fit, nicely, with, a, little, room, to, grow,...   \n",
       "2  [i, bought, this, for, my, sister, who, is, do...   \n",
       "\n",
       "                                              vwords  \n",
       "0  [we, purchased, bedding, because, we, loved, c...  \n",
       "1  [fit, nicely, with, little, room, grow, , , ve...  \n",
       "2  [bought, my, sister, who, doing, koalas, her, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopWords=['the','a','and','or', 'it', 'this', 'of', 'an', 'as', 'in', 'on', 'is', 'are', 'to', 'was', 'for', 'then', 'i']\n",
    "    \n",
    "stopWordsRemover = StopWordsRemover(inputCol='words', outputCol='vwords', stopWords=stopWords)\n",
    "vwords = stopWordsRemover.transform(words)\n",
    "\n",
    "vwords.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bag of Words Features\n",
    "\n",
    "Finally we simply count the number of occurances of all words within the reviews. Again we can simply use a Transformer from PySpark to perform that task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countVectorizer = CountVectorizer(inputCol='vwords', outputCol='features', minDF=2.0)\n",
    "countVectorizerModel = countVectorizer.fit(vwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Vocabulary\n",
    "\n",
    "The countVectorizerModel contains an implcit vocabulary containing all words. This can be useful for mapping features back to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'', u'my', u'with', u'that', u'have', u'we', u'so', u'great', u't', u'baby', u'not', u'very', u'but', u's', u'they', u'one', u'you', u'she', u'love', u'these', u'he', u'when', u'would', u'can', u'them', u'her', u'use', u'be', u'just', u'at', u'old', u'all', u'product', u'our', u'up', u'had', u'easy', u'loves', u'out', u'like', u'little', u'has', u'bought', u'well', u'son', u'daughter', u'good', u'get', u'will', u'only']\n"
     ]
    }
   ],
   "source": [
    "print countVectorizerModel.vocabulary[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy up DataFrame\n",
    "\n",
    "We now carry so many columns inside the DataFrame, let's remove some intermediate columns to get more focus on our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>vwords</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SoHo Bug's Party Baby Crib Nursery Bedding Set...</td>\n",
       "      <td>We purchased this bedding because we loved the...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[we, purchased, bedding, because, we, loved, c...</td>\n",
       "      <td>(2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...</td>\n",
       "      <td>Fit nicely with a little room to grow   VERY S...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[fit, nicely, with, little, room, grow, , , ve...</td>\n",
       "      <td>(4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...</td>\n",
       "      <td>I bought this for my sister who is doing koala...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[bought, my, sister, who, doing, koalas, her, ...</td>\n",
       "      <td>(3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  SoHo Bug's Party Baby Crib Nursery Bedding Set...   \n",
       "1  Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...   \n",
       "2  Babysoy Unisex Baby Oh Soy Bundler - Eggplant ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  We purchased this bedding because we loved the...       5        1.0   \n",
       "1  Fit nicely with a little room to grow   VERY S...       5        1.0   \n",
       "2  I bought this for my sister who is doing koala...       5        1.0   \n",
       "\n",
       "                                              vwords  \\\n",
       "0  [we, purchased, bedding, because, we, loved, c...   \n",
       "1  [fit, nicely, with, little, room, grow, , , ve...   \n",
       "2  [bought, my, sister, who, doing, koalas, her, ...   \n",
       "\n",
       "                                            features  \n",
       "0  (2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, ...  \n",
       "1  (4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "2  (3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = countVectorizerModel.transform(vwords).drop('words')\n",
    "\n",
    "features.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train Data / Test Data\n",
    "\n",
    "Now let's do the usual split of our data into a training data set and a validation data set. Let's use 80% of all reviews for training and 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: 23781\n",
      "test_data: 5984\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = features.randomSplit([0.8,0.2], seed=0)\n",
    "\n",
    "print \"train_data: %d\" % train_data.count()\n",
    "print \"test_data: %d\" % test_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier\n",
    "\n",
    "There are many different classification algorithms out there. We will use a LogisticRegression, of course a DecisionTreeClassifier could be another interesting option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import *\n",
    "\n",
    "logisticRegression = LogisticRegression(featuresCol='features',labelCol='sentiment')\n",
    "logisticModel = logisticRegression.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Model\n",
    "The LogisticRegressionModel also uses coefficients mapped to individual words. Let's have a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00425415  0.08691081  0.05572719  0.02105409  0.04835519  0.04449103\n",
      "  0.0879977   0.29522709 -0.13587291  0.06643145 -0.40355055  0.0250124\n",
      " -0.03450168  0.03922628  0.01034398  0.03779361  0.00164203  0.06741657\n",
      "  0.30557325  0.06181389]\n"
     ]
    }
   ],
   "source": [
    "print logisticModel.coefficients.toArray()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number positive weights 6935\n",
      "Number negative weights 3905\n"
     ]
    }
   ],
   "source": [
    "numPositiveWeights = len(filter(lambda x: x > 0, logisticModel.coefficients.toArray()))\n",
    "numNegativeWeights = len(filter(lambda x: x < 0, logisticModel.coefficients.toArray()))\n",
    "\n",
    "print \"Number positive weights %d\" % numPositiveWeights\n",
    "print \"Number negative weights %d\" % numNegativeWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Weights of some Words\n",
    "\n",
    "Let's check how coefficients look like for some clearly positive or negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good : 0.141940\n",
      "great : 0.295227\n",
      "bad : -0.339597\n",
      "ugly : -0.447269\n"
     ]
    }
   ],
   "source": [
    "def print_word_weight(word):\n",
    "    index = countVectorizerModel.vocabulary.index(word)\n",
    "    weight = logisticModel.coefficients[index]\n",
    "    print '%s : %f' % (word, weight)\n",
    "    \n",
    "print_word_weight('good')\n",
    "print_word_weight('great')    \n",
    "print_word_weight('bad')\n",
    "print_word_weight('ugly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Extreme Words\n",
    "\n",
    "Let us try to find the most positive and most negative word according to the weights. This can be achieved using numpy argmin function to find the index and the vocabulary to map the index to the actual word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst word: positon  value -3.163343\n",
      "Best word: wiser value 2.061051\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "worstWordIndex = np.argmin(logisticModel.coefficients.toArray())\n",
    "worstWord = countVectorizerModel.vocabulary[worstWordIndex]\n",
    "worstWeight = logisticModel.coefficients[worstWordIndex]\n",
    "print \"Worst word: %s  value %f\" % (worstWord, worstWeight)\n",
    "\n",
    "bestWordIndex = np.argmax(logisticModel.coefficients.toArray())\n",
    "bestWord = countVectorizerModel.vocabulary[bestWordIndex]\n",
    "bestWeight = logisticModel.coefficients[bestWordIndex]\n",
    "print \"Best word: %s value %f\" % (bestWord, bestWeight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>27454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my</td>\n",
       "      <td>15368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>with</td>\n",
       "      <td>8634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that</td>\n",
       "      <td>7602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have</td>\n",
       "      <td>7221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>great</td>\n",
       "      <td>7166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>so</td>\n",
       "      <td>6968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t</td>\n",
       "      <td>6209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>very</td>\n",
       "      <td>6190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>baby</td>\n",
       "      <td>6134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  count\n",
       "0         27454\n",
       "1     my  15368\n",
       "2   with   8634\n",
       "3   that   7602\n",
       "4   have   7221\n",
       "5  great   7166\n",
       "6     so   6968\n",
       "7      t   6209\n",
       "8   very   6190\n",
       "9   baby   6134"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_freq = features.select(explode('vwords').alias('word'),'review') \\\n",
    "     .distinct() \\\n",
    "     .groupBy('word').count()\n",
    "\n",
    "doc_freq.orderBy(col('count').desc()).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions\n",
    "\n",
    "The primary idea is of course to make predictions of the sentiment using the learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/python/pyspark/ml/classification.py:207: UserWarning: weights is deprecated. Use coefficients instead.\n",
      "  warnings.warn(\"weights is deprecated. Use coefficients instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>vwords</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Awesome product does its job  been having it f...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[awesome, product, does, its, job, , been, hav...</td>\n",
       "      <td>[-4.59277428694, 4.59277428694]</td>\n",
       "      <td>[0.0100232477843, 0.989976752216]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Fits at least 2 Dr  Brown bottles with nipples...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[fits, at, least, 2, dr, , brown, bottles, wit...</td>\n",
       "      <td>[-4.67755595987, 4.67755595987]</td>\n",
       "      <td>[0.00921599529836, 0.990784004702]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Good productPro   very sturdy and no assembly ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[good, productpro, , , very, sturdy, no, assem...</td>\n",
       "      <td>[-2.51569799721, 2.51569799721]</td>\n",
       "      <td>[0.0747649931555, 0.925235006845]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Reasonable price  Very sturdy with option to r...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[reasonable, price, , very, sturdy, with, opti...</td>\n",
       "      <td>[-3.94537175885, 3.94537175885]</td>\n",
       "      <td>[0.0189769334697, 0.98102306653]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>She loves it   She can pull up on it and it is...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[she, loves, , , she, can, pull, up, heavy, en...</td>\n",
       "      <td>[-1.90070148925, 1.90070148925]</td>\n",
       "      <td>[0.130029100226, 0.869970899774]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>The dinosaur is exactly as shown and arrived m...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[dinosaur, exactly, shown, arrived, more, than...</td>\n",
       "      <td>[-2.54981182416, 2.54981182416]</td>\n",
       "      <td>[0.0724391281993, 0.927560871801]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>These are fabulous   We just moved into a new ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[these, fabulous, , , we, just, moved, into, n...</td>\n",
       "      <td>[-3.39417881657, 3.39417881657]</td>\n",
       "      <td>[0.0324778871925, 0.967522112808]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>This is a great gate   It fits perfectly aroun...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[great, gate, , , fits, perfectly, around, my,...</td>\n",
       "      <td>[-4.32541824417, 4.32541824417]</td>\n",
       "      <td>[0.0130553204062, 0.986944679594]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>We bought this to cover our daughter s car sea...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[we, bought, cover, our, daughter, s, car, sea...</td>\n",
       "      <td>[-3.43093188572, 3.43093188572]</td>\n",
       "      <td>[0.031342627589, 0.968657372411]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>We have been housesitting for a couple who ins...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[we, have, been, housesitting, couple, who, in...</td>\n",
       "      <td>[-3.18373914439, 3.18373914439]</td>\n",
       "      <td>[0.0397822539864, 0.960217746014]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name                                             review  rating  sentiment  \\\n",
       "0       Awesome product does its job  been having it f...       5        1.0   \n",
       "1       Fits at least 2 Dr  Brown bottles with nipples...       5        1.0   \n",
       "2       Good productPro   very sturdy and no assembly ...       4        1.0   \n",
       "3       Reasonable price  Very sturdy with option to r...       5        1.0   \n",
       "4       She loves it   She can pull up on it and it is...       5        1.0   \n",
       "5       The dinosaur is exactly as shown and arrived m...       5        1.0   \n",
       "6       These are fabulous   We just moved into a new ...       5        1.0   \n",
       "7       This is a great gate   It fits perfectly aroun...       5        1.0   \n",
       "8       We bought this to cover our daughter s car sea...       5        1.0   \n",
       "9       We have been housesitting for a couple who ins...       5        1.0   \n",
       "\n",
       "                                              vwords  \\\n",
       "0  [awesome, product, does, its, job, , been, hav...   \n",
       "1  [fits, at, least, 2, dr, , brown, bottles, wit...   \n",
       "2  [good, productpro, , , very, sturdy, no, assem...   \n",
       "3  [reasonable, price, , very, sturdy, with, opti...   \n",
       "4  [she, loves, , , she, can, pull, up, heavy, en...   \n",
       "5  [dinosaur, exactly, shown, arrived, more, than...   \n",
       "6  [these, fabulous, , , we, just, moved, into, n...   \n",
       "7  [great, gate, , , fits, perfectly, around, my,...   \n",
       "8  [we, bought, cover, our, daughter, s, car, sea...   \n",
       "9  [we, have, been, housesitting, couple, who, in...   \n",
       "\n",
       "                     rawPrediction                         probability  \\\n",
       "0  [-4.59277428694, 4.59277428694]   [0.0100232477843, 0.989976752216]   \n",
       "1  [-4.67755595987, 4.67755595987]  [0.00921599529836, 0.990784004702]   \n",
       "2  [-2.51569799721, 2.51569799721]   [0.0747649931555, 0.925235006845]   \n",
       "3  [-3.94537175885, 3.94537175885]    [0.0189769334697, 0.98102306653]   \n",
       "4  [-1.90070148925, 1.90070148925]    [0.130029100226, 0.869970899774]   \n",
       "5  [-2.54981182416, 2.54981182416]   [0.0724391281993, 0.927560871801]   \n",
       "6  [-3.39417881657, 3.39417881657]   [0.0324778871925, 0.967522112808]   \n",
       "7  [-4.32541824417, 4.32541824417]   [0.0130553204062, 0.986944679594]   \n",
       "8  [-3.43093188572, 3.43093188572]    [0.031342627589, 0.968657372411]   \n",
       "9  [-3.18373914439, 3.18373914439]   [0.0397822539864, 0.960217746014]   \n",
       "\n",
       "   prediction  \n",
       "0         1.0  \n",
       "1         1.0  \n",
       "2         1.0  \n",
       "3         1.0  \n",
       "4         1.0  \n",
       "5         1.0  \n",
       "6         1.0  \n",
       "7         1.0  \n",
       "8         1.0  \n",
       "9         1.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = logisticModel.transform(test_data)\n",
    "\n",
    "pred.drop('features').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most Positive Review\n",
    "\n",
    "Using the column rawPrediction, we can find the review which has the highest positive prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>vwords</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hands Free Bottle Holder Multi-Purpose Bib</td>\n",
       "      <td>After we had twins I had a hard time producing...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[after, we, had, twins, had, hard, time, produ...</td>\n",
       "      <td>(12.0, 4.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 0.0,...</td>\n",
       "      <td>[-12.0156696708, 12.0156696708]</td>\n",
       "      <td>[6.04864837798e-06, 0.999993951352]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maxi-Cosi Priori Convertible Car Seat - Penguin</td>\n",
       "      <td>My daughter is very small for her age  She is ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[my, daughter, very, small, her, age, , she, 1...</td>\n",
       "      <td>(29.0, 5.0, 4.0, 7.0, 3.0, 14.0, 1.0, 0.0, 5.0...</td>\n",
       "      <td>[-10.679292409, 10.679292409]</td>\n",
       "      <td>[2.30161267337e-05, 0.999976983873]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evenflo Portable Ultrasaucer</td>\n",
       "      <td>This is a lifesaver     My 5 month old loves t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[lifesaver, , , , , my, 5, month, old, loves, ...</td>\n",
       "      <td>(27.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0,...</td>\n",
       "      <td>[-9.0994326238, 9.0994326238]</td>\n",
       "      <td>[0.000111716700974, 0.999888283299]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edushape Edu-Tiles 25 Piece Solid Play Mat wit...</td>\n",
       "      <td>I purchased these foam squares to create the p...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[purchased, these, foam, squares, create, path...</td>\n",
       "      <td>(17.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0,...</td>\n",
       "      <td>[-8.96044348875, 8.96044348875]</td>\n",
       "      <td>[0.000128372820199, 0.99987162718]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fisher-Price Ocean Wonders Aquarium Bouncer</td>\n",
       "      <td>this is a must have product  the soothing vibr...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[must, have, product, , soothing, vibrator, se...</td>\n",
       "      <td>(6.0, 1.0, 0.0, 2.0, 2.0, 1.0, 3.0, 1.0, 0.0, ...</td>\n",
       "      <td>[-8.80785806875, 8.80785806875]</td>\n",
       "      <td>[0.000149530883059, 0.999850469117]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Golden Asian Silky Baby Crib Nursery Bedding S...</td>\n",
       "      <td>I must say I was apprehensive of buying the be...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[must, say, apprehensive, buying, bedding, due...</td>\n",
       "      <td>(19.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0,...</td>\n",
       "      <td>[-8.06884580403, 8.06884580403]</td>\n",
       "      <td>[0.000313046473905, 0.999686953526]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0         Hands Free Bottle Holder Multi-Purpose Bib   \n",
       "1    Maxi-Cosi Priori Convertible Car Seat - Penguin   \n",
       "2                       Evenflo Portable Ultrasaucer   \n",
       "3  Edushape Edu-Tiles 25 Piece Solid Play Mat wit...   \n",
       "4        Fisher-Price Ocean Wonders Aquarium Bouncer   \n",
       "5  Golden Asian Silky Baby Crib Nursery Bedding S...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  After we had twins I had a hard time producing...       5        1.0   \n",
       "1  My daughter is very small for her age  She is ...       5        1.0   \n",
       "2  This is a lifesaver     My 5 month old loves t...       5        1.0   \n",
       "3  I purchased these foam squares to create the p...       5        1.0   \n",
       "4  this is a must have product  the soothing vibr...       5        1.0   \n",
       "5  I must say I was apprehensive of buying the be...       5        1.0   \n",
       "\n",
       "                                              vwords  \\\n",
       "0  [after, we, had, twins, had, hard, time, produ...   \n",
       "1  [my, daughter, very, small, her, age, , she, 1...   \n",
       "2  [lifesaver, , , , , my, 5, month, old, loves, ...   \n",
       "3  [purchased, these, foam, squares, create, path...   \n",
       "4  [must, have, product, , soothing, vibrator, se...   \n",
       "5  [must, say, apprehensive, buying, bedding, due...   \n",
       "\n",
       "                                            features  \\\n",
       "0  (12.0, 4.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 0.0,...   \n",
       "1  (29.0, 5.0, 4.0, 7.0, 3.0, 14.0, 1.0, 0.0, 5.0...   \n",
       "2  (27.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0,...   \n",
       "3  (17.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0,...   \n",
       "4  (6.0, 1.0, 0.0, 2.0, 2.0, 1.0, 3.0, 1.0, 0.0, ...   \n",
       "5  (19.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0,...   \n",
       "\n",
       "                     rawPrediction                          probability  \\\n",
       "0  [-12.0156696708, 12.0156696708]  [6.04864837798e-06, 0.999993951352]   \n",
       "1    [-10.679292409, 10.679292409]  [2.30161267337e-05, 0.999976983873]   \n",
       "2    [-9.0994326238, 9.0994326238]  [0.000111716700974, 0.999888283299]   \n",
       "3  [-8.96044348875, 8.96044348875]   [0.000128372820199, 0.99987162718]   \n",
       "4  [-8.80785806875, 8.80785806875]  [0.000149530883059, 0.999850469117]   \n",
       "5  [-8.06884580403, 8.06884580403]  [0.000313046473905, 0.999686953526]   \n",
       "\n",
       "   prediction  \n",
       "0         1.0  \n",
       "1         1.0  \n",
       "2         1.0  \n",
       "3         1.0  \n",
       "4         1.0  \n",
       "5         1.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract one component from a Vectors\n",
    "extract_from_vector = udf(lambda v,i : float(v[i]), FloatType())\n",
    "\n",
    "positives = pred.orderBy(extract_from_vector(pred.rawPrediction,lit(1)).desc())\n",
    "\n",
    "positives.limit(6).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Prediction\n",
    "\n",
    "Again we want to assess the performance of the prediction model. This can be done using the builtin class BinaryClassificationEvaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.946327339714\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import *\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='sentiment')\n",
    "result = evaluator.evaluate(pred)\n",
    "\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Evaluator\n",
    "\n",
    "We want to use a different metric namely accuracy. Accuracy is defined as\n",
    "\n",
    "    number_correct_predictions / total_number_predictions\n",
    "    \n",
    "First let us directly calculate that metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.904412\n"
     ]
    }
   ],
   "source": [
    "num_total = pred.count()\n",
    "num_correct = pred.filter(pred.sentiment == pred.prediction).count()\n",
    "\n",
    "model_accuracy = float(num_correct) / num_total\n",
    "\n",
    "print \"Model Accuracy: %f\" % (float(num_correct) / num_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Dummy Predictor\n",
    "\n",
    "It is always interesting to see how a trivial prediction performs. The trivial predictor simply predicts the most common class for all objects. In this case this would be a positive review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.850267\n"
     ]
    }
   ],
   "source": [
    "num_total = pred.count()\n",
    "num_positive = pred.filter(pred.sentiment == 1.0).count()\n",
    "\n",
    "baseline_accuracy = float(num_positive) / num_total\n",
    "\n",
    "print \"Baseline Accuracy: %f\" % (float(num_positive) / num_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Evaluator\n",
    "\n",
    "Now let us create a new Evaluator class implementing accuracy as the relevant Metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AccuracyClassificationEvaluator(Evaluator):\n",
    "    def __init__(self, predictionCol='prediction', labelCol='label'):\n",
    "        super(Evaluator,self).__init__()\n",
    "        self.predictionCol = predictionCol\n",
    "        self.labelCol = labelCol\n",
    "    \n",
    "    def _evaluate(self, dataset):\n",
    "        num_total = dataset.count()\n",
    "        num_correct = dataset.filter(col(self.labelCol) == col(self.predictionCol)).count()\n",
    "        accuracy = float(num_correct) / num_total\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904411764706\n"
     ]
    }
   ],
   "source": [
    "evaluator = AccuracyClassificationEvaluator(labelCol='sentiment')\n",
    "\n",
    "print evaluator.evaluate(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweak Hyper Parameters\n",
    "\n",
    "Again we want to improve overall performance by tweaking model parameters. So first let's see which parameters are available for tweaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n",
      "featuresCol: features column name. (default: features)\n",
      "fitIntercept: whether to fit an intercept term. (default: True)\n",
      "labelCol: label column name. (default: label)\n",
      "maxIter: max number of iterations (>= 0). (default: 100)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\n",
      "rawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\n",
      "regParam: regularization parameter (>= 0). (default: 0.1)\n",
      "standardization: whether to standardize the training features before fitting the model. (default: True)\n",
      "threshold: Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match. (default: 0.5)\n",
      "thresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values >= 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class' threshold. (undefined)\n",
      "tol: the convergence tolerance for iterative algorithms. (default: 1e-06)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "print LogisticRegression().explainParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try some different parameters and check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC = 0.931838\n",
      "Model Accuracy = 0.912767\n"
     ]
    }
   ],
   "source": [
    "logisticRegression2 = LogisticRegression(featuresCol='features',labelCol='sentiment')\n",
    "logisticRegression2.setRegParam(0.01).setMaxIter(100)\n",
    "logisticModel2 = logisticRegression2.fit(train_data)\n",
    "\n",
    "pred = logisticModel2.transform(test_data)\n",
    "\n",
    "roc_evaluator = BinaryClassificationEvaluator(labelCol='sentiment', metricName=\"areaUnderROC\")\n",
    "acc_evaluator = AccuracyClassificationEvaluator(labelCol='sentiment')\n",
    "\n",
    "print \"areaUnderROC = %f\" % roc_evaluator.evaluate(pred)\n",
    "print \"Model Accuracy = %f\" % acc_evaluator.evaluate(pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding best Hyper Parameters\n",
    "\n",
    "So we got an improvement, but what would be best? We need to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_param = 0.000000\n",
      "    areaUnderROC = 0.894418\n",
      "    Model Accuracy = 0.899398\n",
      "reg_param = 0.000100\n",
      "    areaUnderROC = 0.908762\n",
      "    Model Accuracy = 0.906250\n",
      "reg_param = 0.010000\n",
      "    areaUnderROC = 0.931838\n",
      "    Model Accuracy = 0.912767\n",
      "reg_param = 1.000000\n",
      "    areaUnderROC = 0.943480\n",
      "    Model Accuracy = 0.861631\n",
      "reg_param = 100.000000\n",
      "    areaUnderROC = 0.906305\n",
      "    Model Accuracy = 0.850267\n"
     ]
    }
   ],
   "source": [
    "for reg_param in [0.0, 0.0001, 0.01, 1.0, 100.0]:\n",
    "    logisticRegression2 = LogisticRegression(featuresCol='features',labelCol='sentiment')\n",
    "    logisticRegression2.setRegParam(reg_param).setMaxIter(100)\n",
    "    logisticModel2 = logisticRegression2.fit(train_data)\n",
    "    \n",
    "    pred = logisticModel2.transform(test_data)\n",
    "    \n",
    "    roc_evaluator = BinaryClassificationEvaluator(labelCol='sentiment', metricName=\"areaUnderROC\")\n",
    "    acc_evaluator = AccuracyClassificationEvaluator(labelCol='sentiment')\n",
    "\n",
    "    print \"reg_param = %f\" % reg_param\n",
    "    print \"    areaUnderROC = %f\" % roc_evaluator.evaluate(pred)\n",
    "    print \"    Model Accuracy = %f\" % acc_evaluator.evaluate(pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParamGridBuilder & CrossValidator\n",
    "\n",
    "Since the selection of hyper parameters is a very common job and might be tedious work, there is some nice support in PySpark to simplify it. It is a two-step approach:\n",
    "1. Use ParamGridBuilder to create a set of parameters to test, possibly for different hyper parameters\n",
    "2. Use a CrossValidator for selecting the best set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regParam=0.0 maxIter=10\n",
      "regParam=0.0001 maxIter=10\n",
      "regParam=0.01 maxIter=10\n",
      "regParam=1.0 maxIter=10\n",
      "regParam=100.0 maxIter=10\n",
      "regParam=0.0 maxIter=100\n",
      "regParam=0.0001 maxIter=100\n",
      "regParam=0.01 maxIter=100\n",
      "regParam=1.0 maxIter=100\n",
      "regParam=100.0 maxIter=100\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import *\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features',labelCol='sentiment')\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.0, 0.0001, 0.01, 1.0, 100.0]) \\\n",
    "    .addGrid(lr.maxIter, [10, 100]) \\\n",
    "    .build()\n",
    "    \n",
    "for pset in param_grid:\n",
    "    params = [\"%s=%s\" % (key.name, str(value)) for (key,value) in pset.items()]\n",
    "    print ' '.join(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904411764706\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol='features',labelCol='sentiment')\n",
    "evaluator = AccuracyClassificationEvaluator(labelCol='sentiment')\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "model = cv.fit(train_data)\n",
    "\n",
    "print evaluator.evaluate(model.transform(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PySpark 2.1 (Python 3.5)",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
