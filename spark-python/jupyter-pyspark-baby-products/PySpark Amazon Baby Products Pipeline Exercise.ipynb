{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "First we load data from HDFS. It is stored as a trivial CSV file with three columns\n",
    "1. product name\n",
    "2. review text\n",
    "3. rating (1 - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "data = spark.read.text(\"s3://dimajix-training/data/amazon_baby\")\n",
    "data = data.select(\n",
    "        split('value',',')[0].alias('name'),\n",
    "        split('value',',')[1].alias('review'),\n",
    "        split('value',',')[2].alias('rating').cast('int')\n",
    ").filter(col('rating').isNotNull())\n",
    "\n",
    "data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train Data / Test Data\n",
    "\n",
    "Now let's do the usual split of our data into a training data set and a validation data set. Let's use 80% of all reviews for training and 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data.randomSplit([0.8,0.2], seed=1)\n",
    "\n",
    "print(\"train_data: %d\" % train_data.count())\n",
    "print(\"test_data: %d\" % test_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Transformer\n",
    "\n",
    "We need a custom Transformer to build the pipeline. The transformer should remove all punctuations from a given column containing text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    import string\n",
    "    for c in string.punctuation:\n",
    "        text = text.replace(c, ' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "class PunctuationCleanupTransformer(Transformer):\n",
    "    def __init__(self, inputCol, outputCol):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.inputCol = inputCol\n",
    "        self.outputCol = outputCol\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        remove_punctuation_udf = udf(remove_punctuations, StringType())\n",
    "        return dataset.withColumn(self.outputCol, remove_punctuation_udf(self.inputCol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Transformer\n",
    "\n",
    "Lets create an instance of the Transformer and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of PunctuationCleanupTransformer and apply it to the data. The result should be stored in clean_data\n",
    "clean_data = ...\n",
    "\n",
    "# Extract a couple of rows, so we can inspect result\n",
    "clean_data.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ML Pipeline\n",
    "\n",
    "Now we have all components for creating an initial ML Pipeline. Remember that we have been using the following components before\n",
    "\n",
    "* Tokenizer - for splitting reviews into words\n",
    "* StopWordRemover - for removing stop words\n",
    "* NGram - for creating NGrams (we'll use two words per n-gram)\n",
    "* CountVectorizer - for creating bag-of-word features from the words\n",
    "* IDF - for creating TF-IDF features from the NGram counts\n",
    "* LogisticRegression - for creating the real model\n",
    "\n",
    "Now we want to add the PunctuationCleanupTransformer. Note that punctuations need to be removed *before* tokenization!\n",
    "\n",
    "You also need to transform the incoming rating (1-5) to a sentiment (0 or 1) and you need to drop reviews with a rating of 3. This can be done using one ore more SQLTransformer instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.classification import *\n",
    "\n",
    "# Define list of stopwords used in StopWordsRemover\n",
    "stopWords=['the','a','and','or', 'it', 'this', 'of', 'an', 'as', 'in', 'on', 'is', 'are', 'to', 'was', 'for', 'then', 'i']\n",
    "\n",
    "stages = [\n",
    "    # You will probably need in some meaningful order and with appropriate arguments\n",
    "    #   CountVectorizer\n",
    "    #   IDF\n",
    "    #   LogisticRegression\n",
    "    #   NGram\n",
    "    #   PunctuationCleanupTransformer\n",
    "    #   SQLTransformer\n",
    "    #   StopWordsRemover\n",
    "    #   Tokenizer\n",
    "]\n",
    "\n",
    "pipe = Pipeline(stages = stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Pipeline Model\n",
    "Using training data, we create a PipelineModel by fitting the Pipeline to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipe.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Data\n",
    "\n",
    "Let us do some predictions of the test data using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.transform(test_data)\n",
    "\n",
    "pred.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "As in the original exercise, we want to use a custom metric for assessing the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Paste AccuracyClassificationEvaluator from last exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Performance\n",
    "\n",
    "With the evaluator we can assess the performance of the prediction and easily compare it to a simple model which always predicts 'positive'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "always_positive = pred.withColumn('prediction',lit(1.0))\n",
    "\n",
    "evaluator = AccuracyClassificationEvaluator(predictionCol='prediction', labelCol='sentiment')\n",
    "\n",
    "print(\"Model Accuracy = %f\" % evaluator.evaluate(pred))\n",
    "print(\"Baseline Accuracy = %f\" % evaluator.evaluate(always_positive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning\n",
    "\n",
    "Again we want to tune some hyper parameters, but this time inside a pipeline. The methodology is the same as before, we can directly include the CrossValidator into the pipeline. But step by step...\n",
    "\n",
    "First let us have a look at all paremeters of a LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LogisticRegression().explainParams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ParamGrid\n",
    "\n",
    "Now we create a param grid that should be used for using different sets of parameters. We want to tweak two parameters again:\n",
    "\n",
    "* regParam should take values in [0.0, 0.0001, 0.01, 1.0, 100.0]\n",
    "* maxIter should take values in [10, 100])\n",
    "\n",
    "In order to create this grid, we first need to create an instance of a LogisticRegression, so we can access its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import *\n",
    "\n",
    "# create LogisticRegression lr\n",
    "lr = LogisticRegression(featuresCol='features',labelCol='sentiment')\n",
    "\n",
    "# Build a param_grid with specified parameters using ParamGridBuilder()\n",
    "param_grid = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline\n",
    "\n",
    "Now we can create a pipeline using a CrossValidator instead of directly using a LogisticRegression. This means the configuration of the Pipeline should match the old one except that a CrossValidator is inserted instead of the LogisticRegression. The CrossValidator works as a wrapper of the regression algorithm.\n",
    "\n",
    "We want to put our own AccuracyClassificationValidator into the CrossValidator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide Evaluator required by CrossValidator\n",
    "evaluator = AccuracyClassificationEvaluator(labelCol='sentiment')\n",
    "\n",
    "# Define list of stopwords used in StopWordsRemover\n",
    "stopWords=['the','a','and','or', 'it', 'this', 'of', 'an', 'as', 'in', 'on', 'is', 'are', 'to', 'was', 'for', 'then', 'i']\n",
    "\n",
    "stages = [\n",
    "    # You will probably need the following stages\n",
    "    #   CountVectorizer\n",
    "    #   CrossValidator\n",
    "    #   IDF\n",
    "    #   NGram\n",
    "    #   PunctuationCleanupTransformer\n",
    "    #   SQLTransformer\n",
    "    #   StopWordsRemover\n",
    "    #   Tokenizer\n",
    "]\n",
    "\n",
    "pipe = Pipeline(stages = stages)\n",
    "\n",
    "# Fit model to pipeline\n",
    "model = pipe.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiment for test data\n",
    "pred = model.transform(test_data)\n",
    "\n",
    "# Evaluate and compare against baseline\n",
    "evaluator = AccuracyClassificationEvaluator(labelCol='sentiment')\n",
    "print(\"Model Accuracy = %f\" % evaluator.evaluate(pred))\n",
    "print(\"Baseline Accuracy = %f\" % evaluator.evaluate(always_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PySpark 2.1 (Python 3.5)",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}