{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "First we load data from HDFS. It is stored as a trivial CSV file with three columns\n",
    "1. product name\n",
    "2. review text\n",
    "3. rating (1 - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>review</td>\n",
       "      <td>rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "schema =  StructType([\n",
    "    StructField('name',StringType(),True),\n",
    "    StructField('review',StringType(), True),\n",
    "    StructField('rating',StringType(), True),\n",
    "])\n",
    "\n",
    "raw_data = spark.read.schema(schema).csv(\"s3a://dimajix-training/data/amazon_baby\")\n",
    "raw_data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Cache Data\n",
    "\n",
    "We need to convert the \"rating\" columns to an integer - but this will obviously fail for the first record, as this one contains the CSV header. So we need to perform some cleanup after trying to convert the data.\n",
    "\n",
    "For helping distributing the workload, we repartition the DataFrame and also cache it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Really happy with this purchase. I was looking...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semanario (7) Little Girls 14k Gold Overlay Ba...</td>\n",
       "      <td>. I am pleased with product. I love the bangle...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neurosmith - Music Blocks with Mozart Music Ca...</td>\n",
       "      <td>It takes a youthful spirit of inquiry and fasc...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fisher Price Nesting Action Vehicles</td>\n",
       "      <td>This is a great toy.  The wheels really work a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = raw_data.withColumn('rating',col('rating').cast(IntegerType())) \\\n",
    "    .filter(col('rating').isNotNull()) \\\n",
    "    .filter(col('review').isNotNull()) \\\n",
    "    .repartition(31) \\\n",
    "    .cache()\n",
    "\n",
    "data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train Data / Test Data\n",
    "\n",
    "Now let's do the usual split of our data into a training data set and a validation data set. Let's use 80% of all reviews for training and 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: 139461\n",
      "test_data: 34861\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = data.randomSplit([0.8,0.2], seed=1)\n",
    "\n",
    "print(\"train_data: %d\" % train_data.count())\n",
    "print(\"test_data: %d\" % test_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Transformer for Removing Punctuations\n",
    "\n",
    "We need a custom Transformer to build the pipeline. The transformer should remove all punctuations from a given column containing text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    import string\n",
    "    for c in string.punctuation:\n",
    "        text = text.replace(c, ' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "class PunctuationCleanupTransformer(Transformer):\n",
    "    def __init__(self, inputCol, outputCol):\n",
    "        \"\"\"\n",
    "        Constructor of PunctuationCleanupTransformer which takes two arguments:\n",
    "        inputCol - name of input column\n",
    "        outputCol - name of output column\n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "        self.inputCol = inputCol\n",
    "        self.outputCol = outputCol\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        \"\"\"\n",
    "        Protecetd _transform method which will be called by the public transform\n",
    "        method. You should not call this method directly.\n",
    "        \"\"\"\n",
    "        remove_punctuation_udf = udf(remove_punctuations, StringType())\n",
    "        return dataset.withColumn(self.outputCol, remove_punctuation_udf(self.inputCol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Transformer\n",
    "\n",
    "Lets create an instance of the Transformer and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>One of baby s first and favorite books  and it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Really happy with this purchase. I was looking...</td>\n",
       "      <td>5</td>\n",
       "      <td>Really happy with this purchase  I was looking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semanario (7) Little Girls 14k Gold Overlay Ba...</td>\n",
       "      <td>. I am pleased with product. I love the bangle...</td>\n",
       "      <td>4</td>\n",
       "      <td>I am pleased with product  I love the bangle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neurosmith - Music Blocks with Mozart Music Ca...</td>\n",
       "      <td>It takes a youthful spirit of inquiry and fasc...</td>\n",
       "      <td>5</td>\n",
       "      <td>It takes a youthful spirit of inquiry and fasc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner = PunctuationCleanupTransformer(inputCol='review', outputCol='clean_review')\n",
    "clean_data = cleaner.transform(data)\n",
    "\n",
    "clean_data.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Transformer for Stemming\n",
    "\n",
    "We need to stem words, and for doing so we use the Python NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def stem_word(words):\n",
    "    ps = PorterStemmer()\n",
    "    return [ps.stem(word) for word in words]\n",
    "\n",
    "\n",
    "class PorterStemmerTransformer(Transformer):\n",
    "    def __init__(self, inputCol, outputCol):\n",
    "        \"\"\"\n",
    "        Constructor of PorterStemmerTransformer which takes two arguments:\n",
    "        inputCol - name of input column\n",
    "        outputCol - name of output column\n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "        self.inputCol = inputCol\n",
    "        self.outputCol = outputCol\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        \"\"\"\n",
    "        Protecetd _transform method which will be called by the public transform\n",
    "        method. You should not call this method directly.\n",
    "        \"\"\"\n",
    "        stem_word_udf = udf(stem_word, ArrayType(StringType()))\n",
    "        return dataset.withColumn(self.outputCol, stem_word_udf(self.inputCol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Transformer\n",
    "\n",
    "Again we want to test the `PorterStemmerTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>words</th>\n",
       "      <th>stemmed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>[one, of, baby's, first, and, favorite, books,...</td>\n",
       "      <td>[one, of, baby', first, and, favorit, books,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Really happy with this purchase. I was looking...</td>\n",
       "      <td>5</td>\n",
       "      <td>[really, happy, with, this, purchase., i, was,...</td>\n",
       "      <td>[realli, happi, with, thi, purchase., i, wa, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semanario (7) Little Girls 14k Gold Overlay Ba...</td>\n",
       "      <td>. I am pleased with product. I love the bangle...</td>\n",
       "      <td>4</td>\n",
       "      <td>[., i, am, pleased, with, product., i, love, t...</td>\n",
       "      <td>[., i, am, pleas, with, product., i, love, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neurosmith - Music Blocks with Mozart Music Ca...</td>\n",
       "      <td>It takes a youthful spirit of inquiry and fasc...</td>\n",
       "      <td>5</td>\n",
       "      <td>[it, takes, a, youthful, spirit, of, inquiry, ...</td>\n",
       "      <td>[it, take, a, youth, spirit, of, inquiri, and,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import *\n",
    "\n",
    "# First we need to Tokenize each line. In order to perform this task, we implement the following steps\n",
    "# 1. Instantiate a Tokenizer instance from pyspark.ml.feature\n",
    "# 2. Transform the raw data using the tokenizer\n",
    "tokenizer = Tokenizer(inputCol='review', outputCol='words')\n",
    "tokenized_data = tokenizer.transform(data)\n",
    "\n",
    "# Then we can instantiate the Stemmer and use it on the words\n",
    "stemmer = PorterStemmerTransformer(inputCol='words', outputCol='stemmed_review')\n",
    "stemmed_data = stemmer.transform(tokenized_data)\n",
    "\n",
    "stemmed_data.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ML Pipeline\n",
    "\n",
    "Now we have all components for creating an initial ML Pipeline. Remember that we have been using the following components before\n",
    "\n",
    "* PunctuationCleanupTransformer - remove punctuations from reviews\n",
    "* Tokenizer - for splitting reviews into words\n",
    "* StopWordRemover - for removing stop words\n",
    "* PorterStemmerTransformer - for stemming words\n",
    "* NGram - for creating NGrams (we'll use two words per n-gram)\n",
    "* CountVectorizer - for creating bag-of-word features from the words\n",
    "* IDF - for creating TF-IDF features from the NGram counts\n",
    "* LogisticRegression - for creating the real model\n",
    "\n",
    "You also need to transform the incoming rating (1-5) to a sentiment (0 or 1) and you need to drop reviews with a rating of 3. This can be done using one ore more SQLTransformer instances. Inside the SQLTransformer instance you simply write SQL code and access the current DataFrame via `__THIS__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.classification import *\n",
    "\n",
    "stopWords = ['the','a','and','or', 'it', 'this', 'of', 'an', 'as', 'in', 'on', 'is', 'are', 'to', 'was', 'for', 'then', 'i']\n",
    "stopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "\n",
    "stages = [\n",
    "    PunctuationCleanupTransformer(inputCol='review', outputCol='clean_review'),\n",
    "    SQLTransformer(statement='SELECT *,CASE WHEN rating < 3 THEN 0.0 ELSE 1.0 END AS sentiment FROM __THIS__ WHERE rating <> 3'),\n",
    "    Tokenizer(inputCol='clean_review', outputCol='words'),\n",
    "    StopWordsRemover(inputCol='words', outputCol='vwords', stopWords=stopWords),\n",
    "    PorterStemmerTransformer(inputCol='vwords', outputCol='stems'),\n",
    "    NGram(inputCol='stems', outputCol='ngrams', n=3),\n",
    "    CountVectorizer(inputCol='ngrams', outputCol='tf', minDF=2.0),\n",
    "    IDF(inputCol='tf', outputCol='features'),\n",
    "    LogisticRegression(featuresCol='features',labelCol='sentiment')\n",
    "]\n",
    "pipe = Pipeline(stages = stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Pipeline Model\n",
    "Using training data, we create a PipelineModel by fitting the Pipeline to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pipe.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Data\n",
    "\n",
    "Let us do some predictions of the test data using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>words</th>\n",
       "      <th>vwords</th>\n",
       "      <th>stems</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>tf</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>My son is now 2 years old, we bought this when...</td>\n",
       "      <td>5</td>\n",
       "      <td>My son is now 2 years old  we bought this when...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[my, son, is, now, 2, years, old, , we, bought...</td>\n",
       "      <td>[son, 2, years, old, , bought, 7, months, , ha...</td>\n",
       "      <td>[son, 2, year, old, , bought, 7, month, , hand...</td>\n",
       "      <td>[son 2, 2 year, year old, old ,  bought, bough...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-204.959520709, 204.959520709]</td>\n",
       "      <td>[9.70981918835e-90, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>We have used this to enclose our wood stove to...</td>\n",
       "      <td>5</td>\n",
       "      <td>We have used this to enclose our wood stove to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[we, have, used, this, to, enclose, our, wood,...</td>\n",
       "      <td>[used, enclose, wood, stove, protect, kids, , ...</td>\n",
       "      <td>[use, enclos, wood, stove, protect, kid, , wor...</td>\n",
       "      <td>[use enclos, enclos wood, wood stove, stove pr...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-183.20946543, 183.20946543]</td>\n",
       "      <td>[2.71106625568e-80, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*SPECIAL PROMOTION*The Art of CureTM *SAFETY K...</td>\n",
       "      <td>So as much as I love all things natural, we we...</td>\n",
       "      <td>5</td>\n",
       "      <td>So as much as I love all things natural  we we...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[so, as, much, as, i, love, all, things, natur...</td>\n",
       "      <td>[much, love, things, natural, , skeptical, pro...</td>\n",
       "      <td>[much, love, thing, natur, , skeptic, product,...</td>\n",
       "      <td>[much love, love thing, thing natur, natur ,  ...</td>\n",
       "      <td>(12.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>(6.36607257235, 0.0, 2.29004869125, 0.0, 4.604...</td>\n",
       "      <td>[-221.223824601, 221.223824601]</td>\n",
       "      <td>[8.38906791721e-97, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100% Solid Wood Safety Rail Guard &amp;bull; Honey...</td>\n",
       "      <td>This was a beautiful piece and fit nicely with...</td>\n",
       "      <td>5</td>\n",
       "      <td>This was a beautiful piece and fit nicely with...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[this, was, a, beautiful, piece, and, fit, nic...</td>\n",
       "      <td>[beautiful, piece, fit, nicely, bunk, beds, , ...</td>\n",
       "      <td>[beauti, piec, fit, nice, bunk, bed, , , easi,...</td>\n",
       "      <td>[beauti piec, piec fit, fit nice, nice bunk, b...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>(0.530506047696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[-83.7198536231, 83.7198536231]</td>\n",
       "      <td>[4.37451133037e-37, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 Handle 8oz. Cup with Flip-It Straw Top, 1-pk...</td>\n",
       "      <td>There's nothing wrong with the cup itself, I l...</td>\n",
       "      <td>1</td>\n",
       "      <td>There s nothing wrong with the cup itself  I l...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[there, s, nothing, wrong, with, the, cup, its...</td>\n",
       "      <td>[nothing, wrong, cup, , love, cup, , make, mis...</td>\n",
       "      <td>[noth, wrong, cup, , love, cup, , make, mistak...</td>\n",
       "      <td>[noth wrong, wrong cup, cup ,  love, love cup,...</td>\n",
       "      <td>(1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.530506047696, 2.05229618447, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[-73.3754559043, 73.3754559043]</td>\n",
       "      <td>[1.35970405776e-32, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2 Red Hens Whole Roost Bag W/ Changing Pad-Che...</td>\n",
       "      <td>I was amazed when I saw how cheap this bag was...</td>\n",
       "      <td>5</td>\n",
       "      <td>I was amazed when I saw how cheap this bag was...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, was, amazed, when, i, saw, how, cheap, thi...</td>\n",
       "      <td>[amazed, saw, cheap, bag, compared, others, ev...</td>\n",
       "      <td>[amaz, saw, cheap, bag, compar, other, even, o...</td>\n",
       "      <td>[amaz saw, saw cheap, cheap bag, bag compar, c...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.530506047696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[-117.820140623, 117.820140623]</td>\n",
       "      <td>[6.78208252795e-52, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2 in 1 Floating Baby Bottle Brush</td>\n",
       "      <td>I have no idea why I even thought of getting t...</td>\n",
       "      <td>1</td>\n",
       "      <td>I have no idea why I even thought of getting t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[i, have, no, idea, why, i, even, thought, of,...</td>\n",
       "      <td>[idea, even, thought, getting, , , exterior, p...</td>\n",
       "      <td>[idea, even, thought, get, , , exterior, packa...</td>\n",
       "      <td>[idea even, even thought, thought get, get ,  ...</td>\n",
       "      <td>(2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(1.06101209539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[30.9777435103, -30.9777435103]</td>\n",
       "      <td>[1.0, 3.51995354342e-14]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24 Sq. Ft. (set of 24 + borders) 'We Sell Mats...</td>\n",
       "      <td>I gave the mats to my daughter's preschool as ...</td>\n",
       "      <td>5</td>\n",
       "      <td>I gave the mats to my daughter s preschool as ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, gave, the, mats, to, my, daughter, s, pres...</td>\n",
       "      <td>[gave, mats, daughter, preschool, gift, , kids...</td>\n",
       "      <td>[gave, mat, daughter, preschool, gift, , kid, ...</td>\n",
       "      <td>[gave mat, mat daughter, daughter preschool, p...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-44.3790407588, 44.3790407588]</td>\n",
       "      <td>[5.32632283843e-20, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 Packs of NUK Replacement Silicone Spout, Clear</td>\n",
       "      <td>These are the best tips on the Nuk Bottles tha...</td>\n",
       "      <td>5</td>\n",
       "      <td>These are the best tips on the Nuk Bottles tha...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[these, are, the, best, tips, on, the, nuk, bo...</td>\n",
       "      <td>[best, tips, nuk, bottles, get, teeth, start, ...</td>\n",
       "      <td>[best, tip, nuk, bottl, get, teeth, start, che...</td>\n",
       "      <td>[best tip, tip nuk, nuk bottl, bottl get, get ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-110.504977111, 110.504977111]</td>\n",
       "      <td>[1.01929106646e-48, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aden + Anais Issie Security Blanket Set Declan...</td>\n",
       "      <td>My 10 month old son is a great sleeper and has...</td>\n",
       "      <td>5</td>\n",
       "      <td>My 10 month old son is a great sleeper and has...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[my, 10, month, old, son, is, a, great, sleepe...</td>\n",
       "      <td>[10, month, old, son, great, sleeper, since, a...</td>\n",
       "      <td>[10, month, old, son, great, sleeper, sinc, ar...</td>\n",
       "      <td>[10 month, month old, old son, son great, grea...</td>\n",
       "      <td>(8.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(4.24404838157, 2.05229618447, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-272.225093454, 272.225093454]</td>\n",
       "      <td>[5.94489347973e-119, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.transform(test_data)\n",
    "\n",
    "pred.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "As in the original exercise, we want to use a custom metric for assessing the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import *\n",
    "\n",
    "class AccuracyClassificationEvaluator(Evaluator):\n",
    "    def __init__(self, predictionCol='prediction', labelCol='label'):\n",
    "        super(Evaluator,self).__init__()\n",
    "        self.predictionCol = predictionCol\n",
    "        self.labelCol = labelCol\n",
    "    \n",
    "    def _evaluate(self, dataset):\n",
    "        num_total = dataset.count()\n",
    "        num_correct = dataset.filter(col(self.labelCol) == col(self.predictionCol)).count()\n",
    "        accuracy = float(num_correct) / num_total\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Performance\n",
    "\n",
    "With the evaluator we can assess the performance of the prediction and easily compare it to a simple model which always predicts 'positive'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num positive reviews: 26740\n",
      "Num negative reviews: 5010\n"
     ]
    }
   ],
   "source": [
    "print(\"Num positive reviews: %d\" % pred.filter(pred.sentiment > 0.5).count())\n",
    "print(\"Num negative reviews: %d\" % pred.filter(pred.sentiment < 0.5).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 0.908787\n",
      "Baseline Accuracy = 0.842205\n"
     ]
    }
   ],
   "source": [
    "always_positive = pred.withColumn('prediction',lit(1.0))\n",
    "\n",
    "evaluator = AccuracyClassificationEvaluator(predictionCol='prediction', labelCol='sentiment')\n",
    "\n",
    "print(\"Model Accuracy = %f\" % evaluator.evaluate(pred))\n",
    "print(\"Baseline Accuracy = %f\" % evaluator.evaluate(always_positive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning\n",
    "\n",
    "The whole pipeline has some parameters which have an influence on the result, i.e. the accuracy. For example the size of the n-grams will probably have a big impact and also the minDF parameter of the CountVecttorizer will probably have some impact. These settings are called \"hyper parameters\", because they are also model parameters, but not learnt directly during the training phase. But which parameters work best?\n",
    "\n",
    "We will use a CrossValidation to select the best set of hyperparameters.\n",
    "\n",
    "First let us have a look at the paremeters of some stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputCol: input column name. (current: stems)\n",
      "n: number of elements per n-gram (>=1) (default: 2, current: 2)\n",
      "outputCol: output column name. (default: NGram_40749b2d35c5c49766c8__output, current: ngrams)\n"
     ]
    }
   ],
   "source": [
    "print(pipe.getStages()[5].explainParams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ParamGrid\n",
    "\n",
    "Now we create a param grid that should be used for using different sets of parameters. We want to tweak two parameters again:\n",
    "\n",
    "* regParam should take values in [0.0, 0.0001, 0.01, 1.0, 100.0]\n",
    "* maxIter should take values in [10, 100])\n",
    "\n",
    "In order to create this grid, we first need to create an instance of a LogisticRegression, so we can access its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import *\n",
    "\n",
    "ngram = pipe.getStages()[5]\n",
    "count = pipe.getStages()[6]\n",
    "\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(ngram.n, [2, 3, 5]) \\\n",
    "    .addGrid(count.minDF, [1, 2, 3, 5]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline\n",
    "\n",
    "Now we can create a pipeline using a CrossValidator instead of directly using a LogisticRegression. This means the configuration of the Pipeline should match the old one except that a CrossValidator is inserted instead of the LogisticRegression. The CrossValidator works as a wrapper of the regression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = AccuracyClassificationEvaluator(labelCol='sentiment')\n",
    "validator = CrossValidator(estimator=pipe, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# Fit model to pipeline\n",
    "model = validator.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 0.909638\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'always_positive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c78fb9eeffc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model Accuracy = %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baseline Accuracy = %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'always_positive' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict sentiment for test data\n",
    "pred = model.transform(test_data)\n",
    "always_positive = pred.withColumn('prediction',lit(1.0))\n",
    "\n",
    "print(\"Model Accuracy = %f\" % evaluator.evaluate(pred))\n",
    "print(\"Baseline Accuracy = %f\" % evaluator.evaluate(always_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PySpark 2.1 (Python 3.5)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
